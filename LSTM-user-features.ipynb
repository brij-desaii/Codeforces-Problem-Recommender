{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8229560,"sourceType":"datasetVersion","datasetId":4880179},{"sourceId":8262607,"sourceType":"datasetVersion","datasetId":4904375}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport os\nfrom tempfile import TemporaryDirectory\nfrom typing import Tuple\n\nimport torch\nfrom torch import nn, Tensor\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nfrom torch.utils.data import dataset\nfrom torchtext.vocab import vocab\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.nn.utils.rnn import pad_sequence\n\nfrom collections import Counter\n\nfrom zipfile import ZipFile\nfrom urllib.request import urlretrieve\n\nimport pandas as pd\nimport numpy as np\n\nimport time","metadata":{"id":"TSj6Zhto6v_y","execution":{"iopub.status.busy":"2024-04-29T20:18:26.739186Z","iopub.execute_input":"2024-04-29T20:18:26.739980Z","iopub.status.idle":"2024-04-29T20:18:26.747011Z","shell.execute_reply.started":"2024-04-29T20:18:26.739939Z","shell.execute_reply":"2024-04-29T20:18:26.745980Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Preprocessing\nIn this section, we'll start by loading the problemLens dataset. We will then construct vocabularies for problem IDs and user IDs, and create sequences of user interactions. These steps lay the groundwork for our recommendation model, converting the data into a format that our model can utilize effectively.\n## 1.1 Loading Dataset\nAt first we will download our dataset to generate our sequences and vocabularies. Then user_id and problem_id values are processesed to fix their data types.","metadata":{"id":"ewsQzPX17M6i"}},{"cell_type":"code","source":"# urlretrieve(\"http://files.grouplens.org/datasets/problemlens/ml-1m.zip\", \"problemlens.zip\")\n# ZipFile(\"problemlens.zip\", \"r\").extractall()","metadata":{"id":"4x3UJlOc7llA","execution":{"iopub.status.busy":"2024-04-29T20:18:26.748605Z","iopub.execute_input":"2024-04-29T20:18:26.748888Z","iopub.status.idle":"2024-04-29T20:18:26.756893Z","shell.execute_reply.started":"2024-04-29T20:18:26.748862Z","shell.execute_reply":"2024-04-29T20:18:26.756013Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"interactions = pd.read_csv(\"/kaggle/input/cm-to-m/user_problem.csv\")\n\ndf_user_features = pd.read_csv(\"/kaggle/input/cm-to-m/user_tags.csv\")\ndf_user_tags = pd.read_csv(\"/kaggle/input/cm-to-m/user_ratings.csv\")\n","metadata":{"id":"ppvDGJzE7MtC","execution":{"iopub.status.busy":"2024-04-29T20:18:26.758092Z","iopub.execute_input":"2024-04-29T20:18:26.758421Z","iopub.status.idle":"2024-04-29T20:18:26.816886Z","shell.execute_reply.started":"2024-04-29T20:18:26.758390Z","shell.execute_reply":"2024-04-29T20:18:26.816124Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"interactions","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:26.819341Z","iopub.execute_input":"2024-04-29T20:18:26.820106Z","iopub.status.idle":"2024-04-29T20:18:26.833466Z","shell.execute_reply.started":"2024-04-29T20:18:26.820070Z","shell.execute_reply":"2024-04-29T20:18:26.832503Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"          user_handle problem_id   timestamp  problem_rating  \\\n0               maspy     1538:D  1626961617          1700.0   \n1               maspy     1538:C  1626959972          1300.0   \n2               maspy     1538:B  1626959819           800.0   \n3               maspy     1538:A  1626959622           800.0   \n4               maspy     1520:G  1626959357          2200.0   \n...               ...        ...         ...             ...   \n27172  celestialcoder     1360:A  1594058431           800.0   \n27173  celestialcoder     1284:A  1594058264           800.0   \n27174  celestialcoder     1375:G  1593962149          2800.0   \n27175  celestialcoder     1375:F  1593898420          2600.0   \n27176  celestialcoder     1375:D  1593891901          1900.0   \n\n                                            problem_tags  \n0      ['constructive algorithms', 'math', 'number th...  \n1      ['binary search', 'data structures', 'math', '...  \n2                                     ['greedy', 'math']  \n3                        ['brute force', 'dp', 'greedy']  \n4      ['brute force', 'dfs and similar', 'graphs', '...  \n...                                                  ...  \n27172                                 ['greedy', 'math']  \n27173                      ['implementation', 'strings']  \n27174  ['brute force', 'constructive algorithms', 'df...  \n27175  ['constructive algorithms', 'games', 'interact...  \n27176  ['brute force', 'constructive algorithms', 'so...  \n\n[27177 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_handle</th>\n      <th>problem_id</th>\n      <th>timestamp</th>\n      <th>problem_rating</th>\n      <th>problem_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>maspy</td>\n      <td>1538:D</td>\n      <td>1626961617</td>\n      <td>1700.0</td>\n      <td>['constructive algorithms', 'math', 'number th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>maspy</td>\n      <td>1538:C</td>\n      <td>1626959972</td>\n      <td>1300.0</td>\n      <td>['binary search', 'data structures', 'math', '...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>maspy</td>\n      <td>1538:B</td>\n      <td>1626959819</td>\n      <td>800.0</td>\n      <td>['greedy', 'math']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>maspy</td>\n      <td>1538:A</td>\n      <td>1626959622</td>\n      <td>800.0</td>\n      <td>['brute force', 'dp', 'greedy']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>maspy</td>\n      <td>1520:G</td>\n      <td>1626959357</td>\n      <td>2200.0</td>\n      <td>['brute force', 'dfs and similar', 'graphs', '...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27172</th>\n      <td>celestialcoder</td>\n      <td>1360:A</td>\n      <td>1594058431</td>\n      <td>800.0</td>\n      <td>['greedy', 'math']</td>\n    </tr>\n    <tr>\n      <th>27173</th>\n      <td>celestialcoder</td>\n      <td>1284:A</td>\n      <td>1594058264</td>\n      <td>800.0</td>\n      <td>['implementation', 'strings']</td>\n    </tr>\n    <tr>\n      <th>27174</th>\n      <td>celestialcoder</td>\n      <td>1375:G</td>\n      <td>1593962149</td>\n      <td>2800.0</td>\n      <td>['brute force', 'constructive algorithms', 'df...</td>\n    </tr>\n    <tr>\n      <th>27175</th>\n      <td>celestialcoder</td>\n      <td>1375:F</td>\n      <td>1593898420</td>\n      <td>2600.0</td>\n      <td>['constructive algorithms', 'games', 'interact...</td>\n    </tr>\n    <tr>\n      <th>27176</th>\n      <td>celestialcoder</td>\n      <td>1375:D</td>\n      <td>1593891901</td>\n      <td>1900.0</td>\n      <td>['brute force', 'constructive algorithms', 'so...</td>\n    </tr>\n  </tbody>\n</table>\n<p>27177 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Drop one or more columns from the DataFrame\ninteractions.drop(columns=['problem_rating', 'problem_tags'], inplace=True)\ninteractions","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:26.834737Z","iopub.execute_input":"2024-04-29T20:18:26.835031Z","iopub.status.idle":"2024-04-29T20:18:26.849247Z","shell.execute_reply.started":"2024-04-29T20:18:26.835006Z","shell.execute_reply":"2024-04-29T20:18:26.848402Z"},"trusted":true},"execution_count":143,"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"          user_handle problem_id   timestamp\n0               maspy     1538:D  1626961617\n1               maspy     1538:C  1626959972\n2               maspy     1538:B  1626959819\n3               maspy     1538:A  1626959622\n4               maspy     1520:G  1626959357\n...               ...        ...         ...\n27172  celestialcoder     1360:A  1594058431\n27173  celestialcoder     1284:A  1594058264\n27174  celestialcoder     1375:G  1593962149\n27175  celestialcoder     1375:F  1593898420\n27176  celestialcoder     1375:D  1593891901\n\n[27177 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_handle</th>\n      <th>problem_id</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>maspy</td>\n      <td>1538:D</td>\n      <td>1626961617</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>maspy</td>\n      <td>1538:C</td>\n      <td>1626959972</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>maspy</td>\n      <td>1538:B</td>\n      <td>1626959819</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>maspy</td>\n      <td>1538:A</td>\n      <td>1626959622</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>maspy</td>\n      <td>1520:G</td>\n      <td>1626959357</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27172</th>\n      <td>celestialcoder</td>\n      <td>1360:A</td>\n      <td>1594058431</td>\n    </tr>\n    <tr>\n      <th>27173</th>\n      <td>celestialcoder</td>\n      <td>1284:A</td>\n      <td>1594058264</td>\n    </tr>\n    <tr>\n      <th>27174</th>\n      <td>celestialcoder</td>\n      <td>1375:G</td>\n      <td>1593962149</td>\n    </tr>\n    <tr>\n      <th>27175</th>\n      <td>celestialcoder</td>\n      <td>1375:F</td>\n      <td>1593898420</td>\n    </tr>\n    <tr>\n      <th>27176</th>\n      <td>celestialcoder</td>\n      <td>1375:D</td>\n      <td>1593891901</td>\n    </tr>\n  </tbody>\n</table>\n<p>27177 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_user_features.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:26.850596Z","iopub.execute_input":"2024-04-29T20:18:26.851028Z","iopub.status.idle":"2024-04-29T20:18:26.879967Z","shell.execute_reply.started":"2024-04-29T20:18:26.850996Z","shell.execute_reply":"2024-04-29T20:18:26.879074Z"},"trusted":true},"execution_count":144,"outputs":[{"execution_count":144,"output_type":"execute_result","data":{"text/plain":"   *special  0user_handle  2-sat  binary search  bitmasks  brute force  \\\n0       NaN         maspy    NaN           32.0      11.0           56   \n1       NaN        wsyear    NaN           25.0      15.0           47   \n2       NaN       LXH-cat    3.0           51.0      23.0           84   \n3       1.0  skittles1412    NaN            3.0       1.0            5   \n4       NaN  PurpleCrayon    4.0           30.0      28.0           77   \n\n   chinese remainder theorem  combinatorics  constructive algorithms  \\\n0                        NaN            6.0                       45   \n1                        NaN           18.0                       61   \n2                        NaN           51.0                      118   \n3                        NaN            NaN                        8   \n4                        NaN           18.0                      101   \n\n   data structures  ...  number theory  probabilities  schedules  \\\n0               34  ...           15.0            NaN        NaN   \n1               46  ...           17.0            3.0        NaN   \n2               94  ...           43.0           18.0        NaN   \n3                1  ...            NaN            NaN        NaN   \n4               68  ...           36.0            4.0        1.0   \n\n   shortest paths  sortings  string suffix structures  strings  \\\n0            12.0        55                       NaN     24.0   \n1             3.0        24                       NaN     11.0   \n2            13.0        54                       4.0     24.0   \n3             NaN         4                       NaN      8.0   \n4             9.0        60                       2.0     41.0   \n\n   ternary search  trees  two pointers  \n0             NaN   18.0          21.0  \n1             2.0   24.0          15.0  \n2             4.0   46.0          29.0  \n3             NaN    1.0           1.0  \n4             3.0   38.0          26.0  \n\n[5 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>*special</th>\n      <th>0user_handle</th>\n      <th>2-sat</th>\n      <th>binary search</th>\n      <th>bitmasks</th>\n      <th>brute force</th>\n      <th>chinese remainder theorem</th>\n      <th>combinatorics</th>\n      <th>constructive algorithms</th>\n      <th>data structures</th>\n      <th>...</th>\n      <th>number theory</th>\n      <th>probabilities</th>\n      <th>schedules</th>\n      <th>shortest paths</th>\n      <th>sortings</th>\n      <th>string suffix structures</th>\n      <th>strings</th>\n      <th>ternary search</th>\n      <th>trees</th>\n      <th>two pointers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>maspy</td>\n      <td>NaN</td>\n      <td>32.0</td>\n      <td>11.0</td>\n      <td>56</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>45</td>\n      <td>34</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>55</td>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>wsyear</td>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>15.0</td>\n      <td>47</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>61</td>\n      <td>46</td>\n      <td>...</td>\n      <td>17.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>2.0</td>\n      <td>24.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>LXH-cat</td>\n      <td>3.0</td>\n      <td>51.0</td>\n      <td>23.0</td>\n      <td>84</td>\n      <td>NaN</td>\n      <td>51.0</td>\n      <td>118</td>\n      <td>94</td>\n      <td>...</td>\n      <td>43.0</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>54</td>\n      <td>4.0</td>\n      <td>24.0</td>\n      <td>4.0</td>\n      <td>46.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>skittles1412</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>PurpleCrayon</td>\n      <td>4.0</td>\n      <td>30.0</td>\n      <td>28.0</td>\n      <td>77</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>101</td>\n      <td>68</td>\n      <td>...</td>\n      <td>36.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>60</td>\n      <td>2.0</td>\n      <td>41.0</td>\n      <td>3.0</td>\n      <td>38.0</td>\n      <td>26.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Replace all NaNs in the DataFrame with zeroes\ndf_user_features.fillna(0, inplace=True)\ndf_user_features.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:26.881058Z","iopub.execute_input":"2024-04-29T20:18:26.881420Z","iopub.status.idle":"2024-04-29T20:18:26.910764Z","shell.execute_reply.started":"2024-04-29T20:18:26.881385Z","shell.execute_reply":"2024-04-29T20:18:26.909952Z"},"trusted":true},"execution_count":145,"outputs":[{"execution_count":145,"output_type":"execute_result","data":{"text/plain":"   *special  0user_handle  2-sat  binary search  bitmasks  brute force  \\\n0       0.0         maspy    0.0           32.0      11.0           56   \n1       0.0        wsyear    0.0           25.0      15.0           47   \n2       0.0       LXH-cat    3.0           51.0      23.0           84   \n3       1.0  skittles1412    0.0            3.0       1.0            5   \n4       0.0  PurpleCrayon    4.0           30.0      28.0           77   \n\n   chinese remainder theorem  combinatorics  constructive algorithms  \\\n0                        0.0            6.0                       45   \n1                        0.0           18.0                       61   \n2                        0.0           51.0                      118   \n3                        0.0            0.0                        8   \n4                        0.0           18.0                      101   \n\n   data structures  ...  number theory  probabilities  schedules  \\\n0               34  ...           15.0            0.0        0.0   \n1               46  ...           17.0            3.0        0.0   \n2               94  ...           43.0           18.0        0.0   \n3                1  ...            0.0            0.0        0.0   \n4               68  ...           36.0            4.0        1.0   \n\n   shortest paths  sortings  string suffix structures  strings  \\\n0            12.0        55                       0.0     24.0   \n1             3.0        24                       0.0     11.0   \n2            13.0        54                       4.0     24.0   \n3             0.0         4                       0.0      8.0   \n4             9.0        60                       2.0     41.0   \n\n   ternary search  trees  two pointers  \n0             0.0   18.0          21.0  \n1             2.0   24.0          15.0  \n2             4.0   46.0          29.0  \n3             0.0    1.0           1.0  \n4             3.0   38.0          26.0  \n\n[5 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>*special</th>\n      <th>0user_handle</th>\n      <th>2-sat</th>\n      <th>binary search</th>\n      <th>bitmasks</th>\n      <th>brute force</th>\n      <th>chinese remainder theorem</th>\n      <th>combinatorics</th>\n      <th>constructive algorithms</th>\n      <th>data structures</th>\n      <th>...</th>\n      <th>number theory</th>\n      <th>probabilities</th>\n      <th>schedules</th>\n      <th>shortest paths</th>\n      <th>sortings</th>\n      <th>string suffix structures</th>\n      <th>strings</th>\n      <th>ternary search</th>\n      <th>trees</th>\n      <th>two pointers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>maspy</td>\n      <td>0.0</td>\n      <td>32.0</td>\n      <td>11.0</td>\n      <td>56</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>45</td>\n      <td>34</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>55</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>wsyear</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>15.0</td>\n      <td>47</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>61</td>\n      <td>46</td>\n      <td>...</td>\n      <td>17.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>24</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>2.0</td>\n      <td>24.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>LXH-cat</td>\n      <td>3.0</td>\n      <td>51.0</td>\n      <td>23.0</td>\n      <td>84</td>\n      <td>0.0</td>\n      <td>51.0</td>\n      <td>118</td>\n      <td>94</td>\n      <td>...</td>\n      <td>43.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>54</td>\n      <td>4.0</td>\n      <td>24.0</td>\n      <td>4.0</td>\n      <td>46.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>skittles1412</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>PurpleCrayon</td>\n      <td>4.0</td>\n      <td>30.0</td>\n      <td>28.0</td>\n      <td>77</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>101</td>\n      <td>68</td>\n      <td>...</td>\n      <td>36.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>60</td>\n      <td>2.0</td>\n      <td>41.0</td>\n      <td>3.0</td>\n      <td>38.0</td>\n      <td>26.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Rename a column in the DataFrame\ndf_user_features.rename(columns={'0user_handle': 'user_id'}, inplace=True)\ninteractions.rename(columns={'user_handle': 'user_id'}, inplace=True)\ndf_user_features.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:26.911851Z","iopub.execute_input":"2024-04-29T20:18:26.912109Z","iopub.status.idle":"2024-04-29T20:18:26.943831Z","shell.execute_reply.started":"2024-04-29T20:18:26.912086Z","shell.execute_reply":"2024-04-29T20:18:26.942777Z"},"trusted":true},"execution_count":146,"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"   *special       user_id  2-sat  binary search  bitmasks  brute force  \\\n0       0.0         maspy    0.0           32.0      11.0           56   \n1       0.0        wsyear    0.0           25.0      15.0           47   \n2       0.0       LXH-cat    3.0           51.0      23.0           84   \n3       1.0  skittles1412    0.0            3.0       1.0            5   \n4       0.0  PurpleCrayon    4.0           30.0      28.0           77   \n\n   chinese remainder theorem  combinatorics  constructive algorithms  \\\n0                        0.0            6.0                       45   \n1                        0.0           18.0                       61   \n2                        0.0           51.0                      118   \n3                        0.0            0.0                        8   \n4                        0.0           18.0                      101   \n\n   data structures  ...  number theory  probabilities  schedules  \\\n0               34  ...           15.0            0.0        0.0   \n1               46  ...           17.0            3.0        0.0   \n2               94  ...           43.0           18.0        0.0   \n3                1  ...            0.0            0.0        0.0   \n4               68  ...           36.0            4.0        1.0   \n\n   shortest paths  sortings  string suffix structures  strings  \\\n0            12.0        55                       0.0     24.0   \n1             3.0        24                       0.0     11.0   \n2            13.0        54                       4.0     24.0   \n3             0.0         4                       0.0      8.0   \n4             9.0        60                       2.0     41.0   \n\n   ternary search  trees  two pointers  \n0             0.0   18.0          21.0  \n1             2.0   24.0          15.0  \n2             4.0   46.0          29.0  \n3             0.0    1.0           1.0  \n4             3.0   38.0          26.0  \n\n[5 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>*special</th>\n      <th>user_id</th>\n      <th>2-sat</th>\n      <th>binary search</th>\n      <th>bitmasks</th>\n      <th>brute force</th>\n      <th>chinese remainder theorem</th>\n      <th>combinatorics</th>\n      <th>constructive algorithms</th>\n      <th>data structures</th>\n      <th>...</th>\n      <th>number theory</th>\n      <th>probabilities</th>\n      <th>schedules</th>\n      <th>shortest paths</th>\n      <th>sortings</th>\n      <th>string suffix structures</th>\n      <th>strings</th>\n      <th>ternary search</th>\n      <th>trees</th>\n      <th>two pointers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>maspy</td>\n      <td>0.0</td>\n      <td>32.0</td>\n      <td>11.0</td>\n      <td>56</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>45</td>\n      <td>34</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>55</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>wsyear</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>15.0</td>\n      <td>47</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>61</td>\n      <td>46</td>\n      <td>...</td>\n      <td>17.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>24</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>2.0</td>\n      <td>24.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>LXH-cat</td>\n      <td>3.0</td>\n      <td>51.0</td>\n      <td>23.0</td>\n      <td>84</td>\n      <td>0.0</td>\n      <td>51.0</td>\n      <td>118</td>\n      <td>94</td>\n      <td>...</td>\n      <td>43.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>54</td>\n      <td>4.0</td>\n      <td>24.0</td>\n      <td>4.0</td>\n      <td>46.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>skittles1412</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>PurpleCrayon</td>\n      <td>4.0</td>\n      <td>30.0</td>\n      <td>28.0</td>\n      <td>77</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>101</td>\n      <td>68</td>\n      <td>...</td>\n      <td>36.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>60</td>\n      <td>2.0</td>\n      <td>41.0</td>\n      <td>3.0</td>\n      <td>38.0</td>\n      <td>26.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df_user_features.shape)\nprint(df_user_features[\"user_id\"].nunique())\nprint(interactions[\"user_id\"].nunique())","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:26.945161Z","iopub.execute_input":"2024-04-29T20:18:26.945490Z","iopub.status.idle":"2024-04-29T20:18:26.956437Z","shell.execute_reply.started":"2024-04-29T20:18:26.945465Z","shell.execute_reply":"2024-04-29T20:18:26.955481Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stdout","text":"(185, 38)\n185\n185\n","output_type":"stream"}]},{"cell_type":"code","source":"# interactions = pd.merge(interactions, df_user_features, on=\"user_id\")\n# print(interactions[\"user_id\"].nunique())\n# print(interactions.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:26.960905Z","iopub.execute_input":"2024-04-29T20:18:26.961180Z","iopub.status.idle":"2024-04-29T20:18:26.965607Z","shell.execute_reply.started":"2024-04-29T20:18:26.961157Z","shell.execute_reply":"2024-04-29T20:18:26.964665Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"# Preventing ids to be written as integer or float data type\n\ninteractions[\"problem_id\"] = interactions[\"problem_id\"].apply(lambda x: f\"problem_{x}\")\ninteractions[\"user_id\"] = interactions[\"user_id\"].apply(lambda x: f\"user_{x}\")\ndf_user_features[\"user_id\"] = df_user_features[\"user_id\"].apply(lambda x: f\"user_{x}\")","metadata":{"id":"eJoH9z2D7L3k","execution":{"iopub.status.busy":"2024-04-29T20:18:26.966761Z","iopub.execute_input":"2024-04-29T20:18:26.967104Z","iopub.status.idle":"2024-04-29T20:18:26.994593Z","shell.execute_reply.started":"2024-04-29T20:18:26.967072Z","shell.execute_reply":"2024-04-29T20:18:26.993867Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"interactions","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:26.995580Z","iopub.execute_input":"2024-04-29T20:18:26.995820Z","iopub.status.idle":"2024-04-29T20:18:27.006461Z","shell.execute_reply.started":"2024-04-29T20:18:26.995800Z","shell.execute_reply":"2024-04-29T20:18:27.005502Z"},"trusted":true},"execution_count":150,"outputs":[{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"                   user_id      problem_id   timestamp\n0               user_maspy  problem_1538:D  1626961617\n1               user_maspy  problem_1538:C  1626959972\n2               user_maspy  problem_1538:B  1626959819\n3               user_maspy  problem_1538:A  1626959622\n4               user_maspy  problem_1520:G  1626959357\n...                    ...             ...         ...\n27172  user_celestialcoder  problem_1360:A  1594058431\n27173  user_celestialcoder  problem_1284:A  1594058264\n27174  user_celestialcoder  problem_1375:G  1593962149\n27175  user_celestialcoder  problem_1375:F  1593898420\n27176  user_celestialcoder  problem_1375:D  1593891901\n\n[27177 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>problem_id</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user_maspy</td>\n      <td>problem_1538:D</td>\n      <td>1626961617</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user_maspy</td>\n      <td>problem_1538:C</td>\n      <td>1626959972</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user_maspy</td>\n      <td>problem_1538:B</td>\n      <td>1626959819</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>user_maspy</td>\n      <td>problem_1538:A</td>\n      <td>1626959622</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>user_maspy</td>\n      <td>problem_1520:G</td>\n      <td>1626959357</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27172</th>\n      <td>user_celestialcoder</td>\n      <td>problem_1360:A</td>\n      <td>1594058431</td>\n    </tr>\n    <tr>\n      <th>27173</th>\n      <td>user_celestialcoder</td>\n      <td>problem_1284:A</td>\n      <td>1594058264</td>\n    </tr>\n    <tr>\n      <th>27174</th>\n      <td>user_celestialcoder</td>\n      <td>problem_1375:G</td>\n      <td>1593962149</td>\n    </tr>\n    <tr>\n      <th>27175</th>\n      <td>user_celestialcoder</td>\n      <td>problem_1375:F</td>\n      <td>1593898420</td>\n    </tr>\n    <tr>\n      <th>27176</th>\n      <td>user_celestialcoder</td>\n      <td>problem_1375:D</td>\n      <td>1593891901</td>\n    </tr>\n  </tbody>\n</table>\n<p>27177 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(interactions.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"YaE-F_nGMwui","outputId":"b121c57d-d8c2-4ebf-ce59-3b1698d98fae","execution":{"iopub.status.busy":"2024-04-29T20:18:27.007679Z","iopub.execute_input":"2024-04-29T20:18:27.008007Z","iopub.status.idle":"2024-04-29T20:18:27.014261Z","shell.execute_reply.started":"2024-04-29T20:18:27.007977Z","shell.execute_reply":"2024-04-29T20:18:27.013298Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"(27177, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_user_features","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:27.015486Z","iopub.execute_input":"2024-04-29T20:18:27.016134Z","iopub.status.idle":"2024-04-29T20:18:27.057535Z","shell.execute_reply.started":"2024-04-29T20:18:27.016103Z","shell.execute_reply":"2024-04-29T20:18:27.056636Z"},"trusted":true},"execution_count":152,"outputs":[{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"     *special              user_id  2-sat  binary search  bitmasks  \\\n0         0.0           user_maspy    0.0           32.0      11.0   \n1         0.0          user_wsyear    0.0           25.0      15.0   \n2         0.0         user_LXH-cat    3.0           51.0      23.0   \n3         1.0    user_skittles1412    0.0            3.0       1.0   \n4         0.0    user_PurpleCrayon    4.0           30.0      28.0   \n..        ...                  ...    ...            ...       ...   \n180       0.0      user_Osmabnlden    0.0           28.0      15.0   \n181       4.0      user_Carmel_Ab1    1.0          100.0      49.0   \n182      26.0     user_valavshonok    0.0           42.0      23.0   \n183       0.0         user_Erinyes    2.0           33.0      20.0   \n184       0.0  user_celestialcoder    0.0            6.0       2.0   \n\n     brute force  chinese remainder theorem  combinatorics  \\\n0             56                        0.0            6.0   \n1             47                        0.0           18.0   \n2             84                        0.0           51.0   \n3              5                        0.0            0.0   \n4             77                        0.0           18.0   \n..           ...                        ...            ...   \n180           51                        2.0           25.0   \n181          226                        2.0           40.0   \n182          106                        0.0           29.0   \n183           54                        2.0            8.0   \n184            9                        0.0            3.0   \n\n     constructive algorithms  data structures  ...  number theory  \\\n0                         45               34  ...           15.0   \n1                         61               46  ...           17.0   \n2                        118               94  ...           43.0   \n3                          8                1  ...            0.0   \n4                        101               68  ...           36.0   \n..                       ...              ...  ...            ...   \n180                       49               29  ...           30.0   \n181                      181              104  ...           99.0   \n182                       86               40  ...           39.0   \n183                       77               26  ...           18.0   \n184                       12                4  ...            4.0   \n\n     probabilities  schedules  shortest paths  sortings  \\\n0              0.0        0.0            12.0        55   \n1              3.0        0.0             3.0        24   \n2             18.0        0.0            13.0        54   \n3              0.0        0.0             0.0         4   \n4              4.0        1.0             9.0        60   \n..             ...        ...             ...       ...   \n180            2.0        0.0             2.0        30   \n181            6.0        0.0            15.0       158   \n182            8.0        5.0            10.0        72   \n183            2.0        1.0             9.0        42   \n184            0.0        0.0             0.0        11   \n\n     string suffix structures  strings  ternary search  trees  two pointers  \n0                         0.0     24.0             0.0   18.0          21.0  \n1                         0.0     11.0             2.0   24.0          15.0  \n2                         4.0     24.0             4.0   46.0          29.0  \n3                         0.0      8.0             0.0    1.0           1.0  \n4                         2.0     41.0             3.0   38.0          26.0  \n..                        ...      ...             ...    ...           ...  \n180                       0.0     26.0             2.0   12.0          18.0  \n181                       3.0    106.0             6.0   28.0          60.0  \n182                       0.0     69.0             1.0   10.0          30.0  \n183                       0.0     11.0             4.0   14.0          21.0  \n184                       0.0      3.0             0.0    3.0           3.0  \n\n[185 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>*special</th>\n      <th>user_id</th>\n      <th>2-sat</th>\n      <th>binary search</th>\n      <th>bitmasks</th>\n      <th>brute force</th>\n      <th>chinese remainder theorem</th>\n      <th>combinatorics</th>\n      <th>constructive algorithms</th>\n      <th>data structures</th>\n      <th>...</th>\n      <th>number theory</th>\n      <th>probabilities</th>\n      <th>schedules</th>\n      <th>shortest paths</th>\n      <th>sortings</th>\n      <th>string suffix structures</th>\n      <th>strings</th>\n      <th>ternary search</th>\n      <th>trees</th>\n      <th>two pointers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>user_maspy</td>\n      <td>0.0</td>\n      <td>32.0</td>\n      <td>11.0</td>\n      <td>56</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>45</td>\n      <td>34</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>55</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>user_wsyear</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>15.0</td>\n      <td>47</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>61</td>\n      <td>46</td>\n      <td>...</td>\n      <td>17.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>24</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>2.0</td>\n      <td>24.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>user_LXH-cat</td>\n      <td>3.0</td>\n      <td>51.0</td>\n      <td>23.0</td>\n      <td>84</td>\n      <td>0.0</td>\n      <td>51.0</td>\n      <td>118</td>\n      <td>94</td>\n      <td>...</td>\n      <td>43.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>54</td>\n      <td>4.0</td>\n      <td>24.0</td>\n      <td>4.0</td>\n      <td>46.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>user_skittles1412</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>user_PurpleCrayon</td>\n      <td>4.0</td>\n      <td>30.0</td>\n      <td>28.0</td>\n      <td>77</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>101</td>\n      <td>68</td>\n      <td>...</td>\n      <td>36.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>60</td>\n      <td>2.0</td>\n      <td>41.0</td>\n      <td>3.0</td>\n      <td>38.0</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>0.0</td>\n      <td>user_Osmabnlden</td>\n      <td>0.0</td>\n      <td>28.0</td>\n      <td>15.0</td>\n      <td>51</td>\n      <td>2.0</td>\n      <td>25.0</td>\n      <td>49</td>\n      <td>29</td>\n      <td>...</td>\n      <td>30.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>30</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>4.0</td>\n      <td>user_Carmel_Ab1</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>49.0</td>\n      <td>226</td>\n      <td>2.0</td>\n      <td>40.0</td>\n      <td>181</td>\n      <td>104</td>\n      <td>...</td>\n      <td>99.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>158</td>\n      <td>3.0</td>\n      <td>106.0</td>\n      <td>6.0</td>\n      <td>28.0</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>26.0</td>\n      <td>user_valavshonok</td>\n      <td>0.0</td>\n      <td>42.0</td>\n      <td>23.0</td>\n      <td>106</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>86</td>\n      <td>40</td>\n      <td>...</td>\n      <td>39.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>72</td>\n      <td>0.0</td>\n      <td>69.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>30.0</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>0.0</td>\n      <td>user_Erinyes</td>\n      <td>2.0</td>\n      <td>33.0</td>\n      <td>20.0</td>\n      <td>54</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>77</td>\n      <td>26</td>\n      <td>...</td>\n      <td>18.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>42</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>4.0</td>\n      <td>14.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>0.0</td>\n      <td>user_celestialcoder</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>9</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>12</td>\n      <td>4</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>11</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>185 rows × 38 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 1.2 Creating Vocabulary\nNow that we have our data ready, it's time to prepare our vocabularies for user IDs and problem IDs. This step will convert the unique IDs into numerical indices that our model can use. The following code snippet accomplishes this task.","metadata":{"id":"zE0CZxBN8IHK"}},{"cell_type":"code","source":"np.random.seed(42)\n# Generating a list of unique problem ids\nproblem_ids = interactions.problem_id.unique()\n\n# Counter is used to feed problems to movive_vocab\nproblem_counter = Counter(problem_ids)\n\n# Genarting vocabulary\nproblem_vocab = vocab(problem_counter, specials=['<unk>'])\n\n# For indexing input ids\nproblem_vocab_stoi = problem_vocab.get_stoi()\n\n# problem to title mapping dictionary\n# problem_title_dict = dict(zip(problems.problem_id, problems.title))\n\n# Similarly generating a vocabulary for user ids\nuser_ids = interactions.user_id.unique()\nuser_counter = Counter(user_ids)\nuser_vocab = vocab(user_counter, specials=['<unk>'])\nuser_vocab_stoi = user_vocab.get_stoi()","metadata":{"id":"rcNNeirg8F2X","execution":{"iopub.status.busy":"2024-04-29T20:18:27.058633Z","iopub.execute_input":"2024-04-29T20:18:27.058948Z","iopub.status.idle":"2024-04-29T20:18:27.245155Z","shell.execute_reply.started":"2024-04-29T20:18:27.058923Z","shell.execute_reply":"2024-04-29T20:18:27.244272Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Generating Sequences\nAll interactions of users are first sorted by their interaction timestamp and then divided into sub sequences to train our model.","metadata":{"id":"Uxhd4YPy9WNX"}},{"cell_type":"code","source":"# Group ratings by user_id in order of increasing unix_timestamp.\nratings_group = interactions.sort_values(by=[\"timestamp\"]).groupby(\"user_id\")\n\ninteractions_data = pd.DataFrame(\n    data={\n        \"user_id\": list(ratings_group.groups.keys()),\n        \"problem_ids\": list(ratings_group.problem_id.apply(list)),\n        \"timestamps\": list(ratings_group.timestamp.apply(list)),\n    }\n)","metadata":{"id":"zvt_l0sWNF_T","execution":{"iopub.status.busy":"2024-04-29T20:18:27.246357Z","iopub.execute_input":"2024-04-29T20:18:27.246633Z","iopub.status.idle":"2024-04-29T20:18:27.284113Z","shell.execute_reply.started":"2024-04-29T20:18:27.246609Z","shell.execute_reply":"2024-04-29T20:18:27.283365Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"interactions_data","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"CmAcQ8fzNPRi","outputId":"f44964e2-645d-4bd7-e974-52ee83f78d75","execution":{"iopub.status.busy":"2024-04-29T20:18:27.285105Z","iopub.execute_input":"2024-04-29T20:18:27.285399Z","iopub.status.idle":"2024-04-29T20:18:27.315668Z","shell.execute_reply.started":"2024-04-29T20:18:27.285375Z","shell.execute_reply":"2024-04-29T20:18:27.314730Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"                   user_id                                        problem_ids  \\\n0           user_21cs01033  [problem_1719:C, problem_1715:B, problem_1624:...   \n1          user_2497201210  [problem_1921:F, problem_1921:G, problem_1837:...   \n2             user_36champ  [problem_1686:A, problem_1686:B, problem_1686:...   \n3           user_874641984  [problem_1914:G1, problem_1914:G2, problem_827...   \n4    user_A_cat_with_a_hat  [problem_1579:D, problem_1829:G, problem_1833:...   \n..                     ...                                                ...   \n180        user_yuanyuxuan  [problem_1393:A, problem_1393:B, problem_1393:...   \n181           user_zeemanz  [problem_1225:D, problem_1208:D, problem_1648:...   \n182       user_zhenghanyun  [problem_1806:C, problem_1561:D1, problem_665:...   \n183             user_zjjws  [problem_1466:A, problem_1466:B, problem_1466:...   \n184            user_zltzlt  [problem_1140:A, problem_1140:B, problem_1140:...   \n\n                                            timestamps  \n0    [1677832155, 1678090610, 1678288460, 167834644...  \n1    [1705376753, 1705386035, 1705460611, 170550065...  \n2    [1657093017, 1657093549, 1657094326, 165761486...  \n3    [1703042317, 1703140815, 1703165485, 170331179...  \n4    [1684523408, 1684678075, 1684956695, 168683971...  \n..                                                 ...  \n180  [1596860896, 1596860923, 1596860954, 159686096...  \n181  [1698036624, 1698049348, 1698063638, 169807262...  \n182  [1679204602, 1679207180, 1679216742, 167928868...  \n183  [1609565701, 1609565720, 1609565752, 160956576...  \n184  [1632182915, 1632182922, 1632183306, 163218412...  \n\n[185 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>problem_ids</th>\n      <th>timestamps</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1719:C, problem_1715:B, problem_1624:...</td>\n      <td>[1677832155, 1678090610, 1678288460, 167834644...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user_2497201210</td>\n      <td>[problem_1921:F, problem_1921:G, problem_1837:...</td>\n      <td>[1705376753, 1705386035, 1705460611, 170550065...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user_36champ</td>\n      <td>[problem_1686:A, problem_1686:B, problem_1686:...</td>\n      <td>[1657093017, 1657093549, 1657094326, 165761486...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>user_874641984</td>\n      <td>[problem_1914:G1, problem_1914:G2, problem_827...</td>\n      <td>[1703042317, 1703140815, 1703165485, 170331179...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>user_A_cat_with_a_hat</td>\n      <td>[problem_1579:D, problem_1829:G, problem_1833:...</td>\n      <td>[1684523408, 1684678075, 1684956695, 168683971...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>user_yuanyuxuan</td>\n      <td>[problem_1393:A, problem_1393:B, problem_1393:...</td>\n      <td>[1596860896, 1596860923, 1596860954, 159686096...</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>user_zeemanz</td>\n      <td>[problem_1225:D, problem_1208:D, problem_1648:...</td>\n      <td>[1698036624, 1698049348, 1698063638, 169807262...</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>user_zhenghanyun</td>\n      <td>[problem_1806:C, problem_1561:D1, problem_665:...</td>\n      <td>[1679204602, 1679207180, 1679216742, 167928868...</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>user_zjjws</td>\n      <td>[problem_1466:A, problem_1466:B, problem_1466:...</td>\n      <td>[1609565701, 1609565720, 1609565752, 160956576...</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1140:A, problem_1140:B, problem_1140:...</td>\n      <td>[1632182915, 1632182922, 1632183306, 163218412...</td>\n    </tr>\n  </tbody>\n</table>\n<p>185 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Sequence length, min history count and window slide size\nsequence_length = 20\nmin_history = 1\nstep_size = 2\n\n# Creating sequences from lists with sliding window\ndef create_sequences(values, window_size, step_size, min_history):\n  sequences = []\n  start_index = 0\n  while len(values[start_index:]) > min_history:\n    seq = values[start_index : start_index + window_size]\n    sequences.append(seq)\n    start_index += step_size\n  return sequences\n\ninteractions_data.problem_ids = interactions_data.problem_ids.apply(\n    lambda ids: create_sequences(ids, sequence_length, step_size, min_history)\n)\n\n\ndel interactions_data[\"timestamps\"]","metadata":{"id":"D3HT8E6jNdID","execution":{"iopub.status.busy":"2024-04-29T20:18:27.317355Z","iopub.execute_input":"2024-04-29T20:18:27.317715Z","iopub.status.idle":"2024-04-29T20:18:27.352262Z","shell.execute_reply.started":"2024-04-29T20:18:27.317683Z","shell.execute_reply":"2024-04-29T20:18:27.351435Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"interactions_data","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"XS8uSzOVNgcD","outputId":"9ead5309-13eb-4327-abe0-58240c0f35dc","execution":{"iopub.status.busy":"2024-04-29T20:18:27.353475Z","iopub.execute_input":"2024-04-29T20:18:27.353794Z","iopub.status.idle":"2024-04-29T20:18:27.604531Z","shell.execute_reply.started":"2024-04-29T20:18:27.353768Z","shell.execute_reply":"2024-04-29T20:18:27.603587Z"},"trusted":true},"execution_count":157,"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"                   user_id                                        problem_ids\n0           user_21cs01033  [[problem_1719:C, problem_1715:B, problem_1624...\n1          user_2497201210  [[problem_1921:F, problem_1921:G, problem_1837...\n2             user_36champ  [[problem_1686:A, problem_1686:B, problem_1686...\n3           user_874641984  [[problem_1914:G1, problem_1914:G2, problem_82...\n4    user_A_cat_with_a_hat  [[problem_1579:D, problem_1829:G, problem_1833...\n..                     ...                                                ...\n180        user_yuanyuxuan  [[problem_1393:A, problem_1393:B, problem_1393...\n181           user_zeemanz  [[problem_1225:D, problem_1208:D, problem_1648...\n182       user_zhenghanyun  [[problem_1806:C, problem_1561:D1, problem_665...\n183             user_zjjws  [[problem_1466:A, problem_1466:B, problem_1466...\n184            user_zltzlt  [[problem_1140:A, problem_1140:B, problem_1140...\n\n[185 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>problem_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user_21cs01033</td>\n      <td>[[problem_1719:C, problem_1715:B, problem_1624...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user_2497201210</td>\n      <td>[[problem_1921:F, problem_1921:G, problem_1837...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user_36champ</td>\n      <td>[[problem_1686:A, problem_1686:B, problem_1686...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>user_874641984</td>\n      <td>[[problem_1914:G1, problem_1914:G2, problem_82...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>user_A_cat_with_a_hat</td>\n      <td>[[problem_1579:D, problem_1829:G, problem_1833...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>user_yuanyuxuan</td>\n      <td>[[problem_1393:A, problem_1393:B, problem_1393...</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>user_zeemanz</td>\n      <td>[[problem_1225:D, problem_1208:D, problem_1648...</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>user_zhenghanyun</td>\n      <td>[[problem_1806:C, problem_1561:D1, problem_665...</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>user_zjjws</td>\n      <td>[[problem_1466:A, problem_1466:B, problem_1466...</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>user_zltzlt</td>\n      <td>[[problem_1140:A, problem_1140:B, problem_1140...</td>\n    </tr>\n  </tbody>\n</table>\n<p>185 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Sub-sequences are exploded.\n# Since there might be more than one sequence for each user.\ninteractions_data_transformed = interactions_data[[\"user_id\", \"problem_ids\"]].explode(\n    \"problem_ids\", ignore_index=True\n)\n\ninteractions_data_transformed.rename(\n    columns={\"problem_ids\": \"sequence_problem_ids\"},\n    inplace=True,\n)","metadata":{"id":"d1OO4GqD8NX0","execution":{"iopub.status.busy":"2024-04-29T20:18:27.605518Z","iopub.execute_input":"2024-04-29T20:18:27.605790Z","iopub.status.idle":"2024-04-29T20:18:27.616448Z","shell.execute_reply.started":"2024-04-29T20:18:27.605766Z","shell.execute_reply":"2024-04-29T20:18:27.615577Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"print(interactions_data_transformed.sample(frac=1).reset_index(drop=True).head())\nprint(interactions_data_transformed.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q21pt9ww9seT","outputId":"248695b0-a409-436c-e060-a9d7e53386ab","execution":{"iopub.status.busy":"2024-04-29T20:18:27.617557Z","iopub.execute_input":"2024-04-29T20:18:27.617887Z","iopub.status.idle":"2024-04-29T20:18:27.630501Z","shell.execute_reply.started":"2024-04-29T20:18:27.617862Z","shell.execute_reply":"2024-04-29T20:18:27.629461Z"},"trusted":true},"execution_count":159,"outputs":[{"name":"stdout","text":"              user_id                               sequence_problem_ids\n0     user_Carmel_Ab1  [problem_1096:C, problem_1661:C, problem_1661:...\n1         user_zltzlt  [problem_1486:C1, problem_1451:E2, problem_145...\n2  user_ventusliberum  [problem_1827:B2, problem_1828:D2, problem_183...\n3       user_geospiza  [problem_1606:A, problem_1606:C, problem_1606:...\n4   user_aniket_kundu  [problem_1304:E, problem_1301:D, problem_1371:...\n(13544, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"interactions_data_transformed","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:27.632034Z","iopub.execute_input":"2024-04-29T20:18:27.632458Z","iopub.status.idle":"2024-04-29T20:18:27.646132Z","shell.execute_reply.started":"2024-04-29T20:18:27.632426Z","shell.execute_reply":"2024-04-29T20:18:27.645287Z"},"trusted":true},"execution_count":160,"outputs":[{"execution_count":160,"output_type":"execute_result","data":{"text/plain":"              user_id                               sequence_problem_ids\n0      user_21cs01033  [problem_1719:C, problem_1715:B, problem_1624:...\n1      user_21cs01033  [problem_1624:A, problem_1742:E, problem_1742:...\n2      user_21cs01033  [problem_1742:B, problem_1802:A, problem_1802:...\n3      user_21cs01033  [problem_1802:B, problem_1779:A, problem_1607:...\n4      user_21cs01033  [problem_1607:E, problem_1804:D, problem_1758:...\n...               ...                                                ...\n13539     user_zltzlt  [problem_1422:C, problem_1422:D, problem_1422:...\n13540     user_zltzlt  [problem_1422:A, problem_1422:B, problem_1421:...\n13541     user_zltzlt  [problem_1421:D, problem_1624:D, problem_1624:...\n13542     user_zltzlt  [problem_1624:F, problem_1624:G, problem_1624:...\n13543     user_zltzlt                   [problem_1624:E, problem_1626:C]\n\n[13544 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>sequence_problem_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1719:C, problem_1715:B, problem_1624:...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1624:A, problem_1742:E, problem_1742:...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1742:B, problem_1802:A, problem_1802:...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1802:B, problem_1779:A, problem_1607:...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1607:E, problem_1804:D, problem_1758:...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13539</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1422:C, problem_1422:D, problem_1422:...</td>\n    </tr>\n    <tr>\n      <th>13540</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1422:A, problem_1422:B, problem_1421:...</td>\n    </tr>\n    <tr>\n      <th>13541</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1421:D, problem_1624:D, problem_1624:...</td>\n    </tr>\n    <tr>\n      <th>13542</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1624:F, problem_1624:G, problem_1624:...</td>\n    </tr>\n    <tr>\n      <th>13543</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1624:E, problem_1626:C]</td>\n    </tr>\n  </tbody>\n</table>\n<p>13544 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"interactions_data_transformed = pd.merge(interactions_data_transformed,df_user_features, on=\"user_id\")\ninteractions_data_transformed","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:27.647280Z","iopub.execute_input":"2024-04-29T20:18:27.648155Z","iopub.status.idle":"2024-04-29T20:18:27.703536Z","shell.execute_reply.started":"2024-04-29T20:18:27.648123Z","shell.execute_reply":"2024-04-29T20:18:27.702645Z"},"trusted":true},"execution_count":161,"outputs":[{"execution_count":161,"output_type":"execute_result","data":{"text/plain":"              user_id                               sequence_problem_ids  \\\n0      user_21cs01033  [problem_1719:C, problem_1715:B, problem_1624:...   \n1      user_21cs01033  [problem_1624:A, problem_1742:E, problem_1742:...   \n2      user_21cs01033  [problem_1742:B, problem_1802:A, problem_1802:...   \n3      user_21cs01033  [problem_1802:B, problem_1779:A, problem_1607:...   \n4      user_21cs01033  [problem_1607:E, problem_1804:D, problem_1758:...   \n...               ...                                                ...   \n13539     user_zltzlt  [problem_1422:C, problem_1422:D, problem_1422:...   \n13540     user_zltzlt  [problem_1422:A, problem_1422:B, problem_1421:...   \n13541     user_zltzlt  [problem_1421:D, problem_1624:D, problem_1624:...   \n13542     user_zltzlt  [problem_1624:F, problem_1624:G, problem_1624:...   \n13543     user_zltzlt                   [problem_1624:E, problem_1626:C]   \n\n       *special  2-sat  binary search  bitmasks  brute force  \\\n0           2.0    0.0           21.0       2.0           43   \n1           2.0    0.0           21.0       2.0           43   \n2           2.0    0.0           21.0       2.0           43   \n3           2.0    0.0           21.0       2.0           43   \n4           2.0    0.0           21.0       2.0           43   \n...         ...    ...            ...       ...          ...   \n13539       1.0    0.0           36.0      34.0           57   \n13540       1.0    0.0           36.0      34.0           57   \n13541       1.0    0.0           36.0      34.0           57   \n13542       1.0    0.0           36.0      34.0           57   \n13543       1.0    0.0           36.0      34.0           57   \n\n       chinese remainder theorem  combinatorics  constructive algorithms  ...  \\\n0                            0.0            7.0                       53  ...   \n1                            0.0            7.0                       53  ...   \n2                            0.0            7.0                       53  ...   \n3                            0.0            7.0                       53  ...   \n4                            0.0            7.0                       53  ...   \n...                          ...            ...                      ...  ...   \n13539                        0.0           22.0                       44  ...   \n13540                        0.0           22.0                       44  ...   \n13541                        0.0           22.0                       44  ...   \n13542                        0.0           22.0                       44  ...   \n13543                        0.0           22.0                       44  ...   \n\n       number theory  probabilities  schedules  shortest paths  sortings  \\\n0               13.0            2.0        1.0             1.0        33   \n1               13.0            2.0        1.0             1.0        33   \n2               13.0            2.0        1.0             1.0        33   \n3               13.0            2.0        1.0             1.0        33   \n4               13.0            2.0        1.0             1.0        33   \n...              ...            ...        ...             ...       ...   \n13539           25.0            2.0        0.0            11.0        40   \n13540           25.0            2.0        0.0            11.0        40   \n13541           25.0            2.0        0.0            11.0        40   \n13542           25.0            2.0        0.0            11.0        40   \n13543           25.0            2.0        0.0            11.0        40   \n\n       string suffix structures  strings  ternary search  trees  two pointers  \n0                           0.0     26.0             5.0    1.0          13.0  \n1                           0.0     26.0             5.0    1.0          13.0  \n2                           0.0     26.0             5.0    1.0          13.0  \n3                           0.0     26.0             5.0    1.0          13.0  \n4                           0.0     26.0             5.0    1.0          13.0  \n...                         ...      ...             ...    ...           ...  \n13539                       3.0     20.0             3.0   46.0          17.0  \n13540                       3.0     20.0             3.0   46.0          17.0  \n13541                       3.0     20.0             3.0   46.0          17.0  \n13542                       3.0     20.0             3.0   46.0          17.0  \n13543                       3.0     20.0             3.0   46.0          17.0  \n\n[13544 rows x 39 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>sequence_problem_ids</th>\n      <th>*special</th>\n      <th>2-sat</th>\n      <th>binary search</th>\n      <th>bitmasks</th>\n      <th>brute force</th>\n      <th>chinese remainder theorem</th>\n      <th>combinatorics</th>\n      <th>constructive algorithms</th>\n      <th>...</th>\n      <th>number theory</th>\n      <th>probabilities</th>\n      <th>schedules</th>\n      <th>shortest paths</th>\n      <th>sortings</th>\n      <th>string suffix structures</th>\n      <th>strings</th>\n      <th>ternary search</th>\n      <th>trees</th>\n      <th>two pointers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1719:C, problem_1715:B, problem_1624:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1624:A, problem_1742:E, problem_1742:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1742:B, problem_1802:A, problem_1802:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1802:B, problem_1779:A, problem_1607:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1607:E, problem_1804:D, problem_1758:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13539</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1422:C, problem_1422:D, problem_1422:...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>13540</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1422:A, problem_1422:B, problem_1421:...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>13541</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1421:D, problem_1624:D, problem_1624:...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>13542</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1624:F, problem_1624:G, problem_1624:...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>13543</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1624:E, problem_1626:C]</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13544 rows × 39 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(interactions_data_transformed.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:27.704650Z","iopub.execute_input":"2024-04-29T20:18:27.704930Z","iopub.status.idle":"2024-04-29T20:18:27.709507Z","shell.execute_reply.started":"2024-04-29T20:18:27.704907Z","shell.execute_reply":"2024-04-29T20:18:27.708562Z"},"trusted":true},"execution_count":162,"outputs":[{"name":"stdout","text":"(13544, 39)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.4 Train Test Split\nThe data is split into training and testing sets. Although considering timestamps could potentially provide a more refined split, for the sake of simplicity, we opt for a random indexing approach.","metadata":{"id":"-0wqTDXi_1vi"}},{"cell_type":"code","source":"# Random indexing\nrandom_selection = np.random.rand(len(interactions_data_transformed.index)) <= 0.85\n\n# Split train data\ndf_train_data = interactions_data_transformed[random_selection]\n\n\n# Split test data\ndf_test_data = interactions_data_transformed[~random_selection]\n","metadata":{"id":"5WOLmSIz9tYQ","execution":{"iopub.status.busy":"2024-04-29T20:18:27.710728Z","iopub.execute_input":"2024-04-29T20:18:27.711066Z","iopub.status.idle":"2024-04-29T20:18:27.720456Z","shell.execute_reply.started":"2024-04-29T20:18:27.711029Z","shell.execute_reply":"2024-04-29T20:18:27.719550Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import MinMaxScaler\n\n# # Get the numerical columns by excluding \"user_id\" and \"sequence_problem_ids\"\n# numerical_columns = df_train_data.drop(columns=['user_id', 'sequence_problem_ids']).columns.tolist()\n\n# # Create MinMaxScaler objects\n# scaler_train = MinMaxScaler()\n\n# # Fit and transform the training data\n# df_train_data.loc[:, numerical_columns] = scaler_train.fit_transform(df_train_data[numerical_columns])\n\n# # Transform the testing data (using parameters learned from training data)\n# df_test_data.loc[:, numerical_columns] = scaler_train.transform(df_test_data[numerical_columns])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:27.721584Z","iopub.execute_input":"2024-04-29T20:18:27.721906Z","iopub.status.idle":"2024-04-29T20:18:27.726392Z","shell.execute_reply.started":"2024-04-29T20:18:27.721870Z","shell.execute_reply":"2024-04-29T20:18:27.725434Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"train_data_raw = df_train_data.values\ntest_data_raw = df_test_data.values","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:27.727745Z","iopub.execute_input":"2024-04-29T20:18:27.728095Z","iopub.status.idle":"2024-04-29T20:18:27.764603Z","shell.execute_reply.started":"2024-04-29T20:18:27.728064Z","shell.execute_reply":"2024-04-29T20:18:27.763812Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"df_train_data","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"j3siVHtCOWSn","outputId":"b966e9a9-b619-4794-ddcc-0f931c2d212b","execution":{"iopub.status.busy":"2024-04-29T20:18:27.770328Z","iopub.execute_input":"2024-04-29T20:18:27.770693Z","iopub.status.idle":"2024-04-29T20:18:27.815414Z","shell.execute_reply.started":"2024-04-29T20:18:27.770669Z","shell.execute_reply":"2024-04-29T20:18:27.814562Z"},"trusted":true},"execution_count":166,"outputs":[{"execution_count":166,"output_type":"execute_result","data":{"text/plain":"              user_id                               sequence_problem_ids  \\\n0      user_21cs01033  [problem_1719:C, problem_1715:B, problem_1624:...   \n1      user_21cs01033  [problem_1624:A, problem_1742:E, problem_1742:...   \n2      user_21cs01033  [problem_1742:B, problem_1802:A, problem_1802:...   \n3      user_21cs01033  [problem_1802:B, problem_1779:A, problem_1607:...   \n5      user_21cs01033  [problem_1758:A, problem_1758:B, problem_1800:...   \n...               ...                                                ...   \n13534     user_zltzlt  [problem_1528:D, problem_538:B, problem_359:B,...   \n13538     user_zltzlt  [problem_1397:B, problem_50:D, problem_1422:C,...   \n13539     user_zltzlt  [problem_1422:C, problem_1422:D, problem_1422:...   \n13540     user_zltzlt  [problem_1422:A, problem_1422:B, problem_1421:...   \n13543     user_zltzlt                   [problem_1624:E, problem_1626:C]   \n\n       *special  2-sat  binary search  bitmasks  brute force  \\\n0           2.0    0.0           21.0       2.0           43   \n1           2.0    0.0           21.0       2.0           43   \n2           2.0    0.0           21.0       2.0           43   \n3           2.0    0.0           21.0       2.0           43   \n5           2.0    0.0           21.0       2.0           43   \n...         ...    ...            ...       ...          ...   \n13534       1.0    0.0           36.0      34.0           57   \n13538       1.0    0.0           36.0      34.0           57   \n13539       1.0    0.0           36.0      34.0           57   \n13540       1.0    0.0           36.0      34.0           57   \n13543       1.0    0.0           36.0      34.0           57   \n\n       chinese remainder theorem  combinatorics  constructive algorithms  ...  \\\n0                            0.0            7.0                       53  ...   \n1                            0.0            7.0                       53  ...   \n2                            0.0            7.0                       53  ...   \n3                            0.0            7.0                       53  ...   \n5                            0.0            7.0                       53  ...   \n...                          ...            ...                      ...  ...   \n13534                        0.0           22.0                       44  ...   \n13538                        0.0           22.0                       44  ...   \n13539                        0.0           22.0                       44  ...   \n13540                        0.0           22.0                       44  ...   \n13543                        0.0           22.0                       44  ...   \n\n       number theory  probabilities  schedules  shortest paths  sortings  \\\n0               13.0            2.0        1.0             1.0        33   \n1               13.0            2.0        1.0             1.0        33   \n2               13.0            2.0        1.0             1.0        33   \n3               13.0            2.0        1.0             1.0        33   \n5               13.0            2.0        1.0             1.0        33   \n...              ...            ...        ...             ...       ...   \n13534           25.0            2.0        0.0            11.0        40   \n13538           25.0            2.0        0.0            11.0        40   \n13539           25.0            2.0        0.0            11.0        40   \n13540           25.0            2.0        0.0            11.0        40   \n13543           25.0            2.0        0.0            11.0        40   \n\n       string suffix structures  strings  ternary search  trees  two pointers  \n0                           0.0     26.0             5.0    1.0          13.0  \n1                           0.0     26.0             5.0    1.0          13.0  \n2                           0.0     26.0             5.0    1.0          13.0  \n3                           0.0     26.0             5.0    1.0          13.0  \n5                           0.0     26.0             5.0    1.0          13.0  \n...                         ...      ...             ...    ...           ...  \n13534                       3.0     20.0             3.0   46.0          17.0  \n13538                       3.0     20.0             3.0   46.0          17.0  \n13539                       3.0     20.0             3.0   46.0          17.0  \n13540                       3.0     20.0             3.0   46.0          17.0  \n13543                       3.0     20.0             3.0   46.0          17.0  \n\n[11510 rows x 39 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>sequence_problem_ids</th>\n      <th>*special</th>\n      <th>2-sat</th>\n      <th>binary search</th>\n      <th>bitmasks</th>\n      <th>brute force</th>\n      <th>chinese remainder theorem</th>\n      <th>combinatorics</th>\n      <th>constructive algorithms</th>\n      <th>...</th>\n      <th>number theory</th>\n      <th>probabilities</th>\n      <th>schedules</th>\n      <th>shortest paths</th>\n      <th>sortings</th>\n      <th>string suffix structures</th>\n      <th>strings</th>\n      <th>ternary search</th>\n      <th>trees</th>\n      <th>two pointers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1719:C, problem_1715:B, problem_1624:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1624:A, problem_1742:E, problem_1742:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1742:B, problem_1802:A, problem_1802:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1802:B, problem_1779:A, problem_1607:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>user_21cs01033</td>\n      <td>[problem_1758:A, problem_1758:B, problem_1800:...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>53</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13534</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1528:D, problem_538:B, problem_359:B,...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>13538</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1397:B, problem_50:D, problem_1422:C,...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>13539</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1422:C, problem_1422:D, problem_1422:...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>13540</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1422:A, problem_1422:B, problem_1421:...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>13543</th>\n      <td>user_zltzlt</td>\n      <td>[problem_1624:E, problem_1626:C]</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>36.0</td>\n      <td>34.0</td>\n      <td>57</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>44</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>17.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11510 rows × 39 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:27.816348Z","iopub.execute_input":"2024-04-29T20:18:27.816595Z","iopub.status.idle":"2024-04-29T20:18:27.909180Z","shell.execute_reply.started":"2024-04-29T20:18:27.816574Z","shell.execute_reply":"2024-04-29T20:18:27.908268Z"},"trusted":true},"execution_count":167,"outputs":[{"execution_count":167,"output_type":"execute_result","data":{"text/plain":"           *special         2-sat  binary search      bitmasks   brute force  \\\ncount  11510.000000  11510.000000   11510.000000  11510.000000  11510.000000   \nmean       3.387055      0.827889      41.143788     20.479235     77.351347   \nstd        5.314561      1.723326      45.978338     20.892296     73.539887   \nmin        0.000000      0.000000       0.000000      0.000000      1.000000   \n25%        0.000000      0.000000      15.000000      7.000000     30.000000   \n50%        1.000000      0.000000      26.000000     14.000000     51.000000   \n75%        4.000000      1.000000      45.000000     26.000000     99.000000   \nmax       30.000000      9.000000     248.000000    120.000000    393.000000   \n\n       chinese remainder theorem  combinatorics  constructive algorithms  \\\ncount               11510.000000   11510.000000             11510.000000   \nmean                    0.528497      18.875065                76.246481   \nstd                     1.046580      19.733837                63.549026   \nmin                     0.000000       0.000000                 3.000000   \n25%                     0.000000       6.000000                36.000000   \n50%                     0.000000      11.000000                53.000000   \n75%                     1.000000      25.000000               102.000000   \nmax                     9.000000      93.000000               325.000000   \n\n       data structures  dfs and similar  ...  number theory  probabilities  \\\ncount     11510.000000     11510.000000  ...   11510.000000   11510.000000   \nmean         51.832841        30.046308  ...      33.813032       3.338749   \nstd          66.966483        41.777531  ...      32.933952       5.034007   \nmin           1.000000         0.000000  ...       0.000000       0.000000   \n25%          17.000000         7.000000  ...      13.000000       0.000000   \n50%          28.000000        17.000000  ...      22.000000       2.000000   \n75%          67.000000        32.000000  ...      47.000000       4.000000   \nmax         413.000000       243.000000  ...     190.000000      26.000000   \n\n          schedules  shortest paths      sortings  string suffix structures  \\\ncount  11510.000000    11510.000000  11510.000000              11510.000000   \nmean       0.385317        9.433449     55.623371                  1.480104   \nstd        0.811557       14.834583     52.439205                  3.448804   \nmin        0.000000        0.000000      1.000000                  0.000000   \n25%        0.000000        2.000000     21.000000                  0.000000   \n50%        0.000000        5.000000     40.000000                  0.000000   \n75%        1.000000       11.000000     72.000000                  1.000000   \nmax        5.000000       92.000000    300.000000                 20.000000   \n\n           strings  ternary search         trees  two pointers  \ncount  11510.00000    11510.000000  11510.000000  11510.000000  \nmean      36.75821        1.564639     19.014944     24.044657  \nstd       36.04365        2.135220     27.605008     24.913539  \nmin        0.00000        0.000000      0.000000      0.000000  \n25%       13.00000        0.000000      4.000000      9.000000  \n50%       22.00000        1.000000      9.000000     16.000000  \n75%       55.00000        2.000000     22.000000     28.000000  \nmax      202.00000        9.000000    156.000000    127.000000  \n\n[8 rows x 37 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>*special</th>\n      <th>2-sat</th>\n      <th>binary search</th>\n      <th>bitmasks</th>\n      <th>brute force</th>\n      <th>chinese remainder theorem</th>\n      <th>combinatorics</th>\n      <th>constructive algorithms</th>\n      <th>data structures</th>\n      <th>dfs and similar</th>\n      <th>...</th>\n      <th>number theory</th>\n      <th>probabilities</th>\n      <th>schedules</th>\n      <th>shortest paths</th>\n      <th>sortings</th>\n      <th>string suffix structures</th>\n      <th>strings</th>\n      <th>ternary search</th>\n      <th>trees</th>\n      <th>two pointers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>...</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.00000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n      <td>11510.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.387055</td>\n      <td>0.827889</td>\n      <td>41.143788</td>\n      <td>20.479235</td>\n      <td>77.351347</td>\n      <td>0.528497</td>\n      <td>18.875065</td>\n      <td>76.246481</td>\n      <td>51.832841</td>\n      <td>30.046308</td>\n      <td>...</td>\n      <td>33.813032</td>\n      <td>3.338749</td>\n      <td>0.385317</td>\n      <td>9.433449</td>\n      <td>55.623371</td>\n      <td>1.480104</td>\n      <td>36.75821</td>\n      <td>1.564639</td>\n      <td>19.014944</td>\n      <td>24.044657</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.314561</td>\n      <td>1.723326</td>\n      <td>45.978338</td>\n      <td>20.892296</td>\n      <td>73.539887</td>\n      <td>1.046580</td>\n      <td>19.733837</td>\n      <td>63.549026</td>\n      <td>66.966483</td>\n      <td>41.777531</td>\n      <td>...</td>\n      <td>32.933952</td>\n      <td>5.034007</td>\n      <td>0.811557</td>\n      <td>14.834583</td>\n      <td>52.439205</td>\n      <td>3.448804</td>\n      <td>36.04365</td>\n      <td>2.135220</td>\n      <td>27.605008</td>\n      <td>24.913539</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>7.000000</td>\n      <td>30.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>36.000000</td>\n      <td>17.000000</td>\n      <td>7.000000</td>\n      <td>...</td>\n      <td>13.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>13.00000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>26.000000</td>\n      <td>14.000000</td>\n      <td>51.000000</td>\n      <td>0.000000</td>\n      <td>11.000000</td>\n      <td>53.000000</td>\n      <td>28.000000</td>\n      <td>17.000000</td>\n      <td>...</td>\n      <td>22.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n      <td>22.00000</td>\n      <td>1.000000</td>\n      <td>9.000000</td>\n      <td>16.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>45.000000</td>\n      <td>26.000000</td>\n      <td>99.000000</td>\n      <td>1.000000</td>\n      <td>25.000000</td>\n      <td>102.000000</td>\n      <td>67.000000</td>\n      <td>32.000000</td>\n      <td>...</td>\n      <td>47.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>11.000000</td>\n      <td>72.000000</td>\n      <td>1.000000</td>\n      <td>55.00000</td>\n      <td>2.000000</td>\n      <td>22.000000</td>\n      <td>28.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>30.000000</td>\n      <td>9.000000</td>\n      <td>248.000000</td>\n      <td>120.000000</td>\n      <td>393.000000</td>\n      <td>9.000000</td>\n      <td>93.000000</td>\n      <td>325.000000</td>\n      <td>413.000000</td>\n      <td>243.000000</td>\n      <td>...</td>\n      <td>190.000000</td>\n      <td>26.000000</td>\n      <td>5.000000</td>\n      <td>92.000000</td>\n      <td>300.000000</td>\n      <td>20.000000</td>\n      <td>202.00000</td>\n      <td>9.000000</td>\n      <td>156.000000</td>\n      <td>127.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 37 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data_raw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8OtEVlihZ9F","outputId":"4bd43552-aadb-453c-fc5f-5bf5ce780c7d","execution":{"iopub.status.busy":"2024-04-29T20:18:27.910385Z","iopub.execute_input":"2024-04-29T20:18:27.910662Z","iopub.status.idle":"2024-04-29T20:18:27.917013Z","shell.execute_reply.started":"2024-04-29T20:18:27.910638Z","shell.execute_reply":"2024-04-29T20:18:27.915923Z"},"trusted":true},"execution_count":168,"outputs":[{"execution_count":168,"output_type":"execute_result","data":{"text/plain":"array([['user_21cs01033',\n        list(['problem_1719:C', 'problem_1715:B', 'problem_1624:A', 'problem_1742:E', 'problem_1742:B', 'problem_1802:A', 'problem_1802:B', 'problem_1779:A', 'problem_1607:E', 'problem_1804:D', 'problem_1758:A', 'problem_1758:B', 'problem_1800:B', 'problem_56:E', 'problem_1760:B', 'problem_1806:C', 'problem_1807:G2', 'problem_1807:G1', 'problem_1733:C', 'problem_1748:B']),\n        2.0, ..., 5.0, 1.0, 13.0],\n       ['user_21cs01033',\n        list(['problem_1624:A', 'problem_1742:E', 'problem_1742:B', 'problem_1802:A', 'problem_1802:B', 'problem_1779:A', 'problem_1607:E', 'problem_1804:D', 'problem_1758:A', 'problem_1758:B', 'problem_1800:B', 'problem_56:E', 'problem_1760:B', 'problem_1806:C', 'problem_1807:G2', 'problem_1807:G1', 'problem_1733:C', 'problem_1748:B', 'problem_1721:C', 'problem_1742:G']),\n        2.0, ..., 5.0, 1.0, 13.0],\n       ['user_21cs01033',\n        list(['problem_1742:B', 'problem_1802:A', 'problem_1802:B', 'problem_1779:A', 'problem_1607:E', 'problem_1804:D', 'problem_1758:A', 'problem_1758:B', 'problem_1800:B', 'problem_56:E', 'problem_1760:B', 'problem_1806:C', 'problem_1807:G2', 'problem_1807:G1', 'problem_1733:C', 'problem_1748:B', 'problem_1721:C', 'problem_1742:G', 'problem_1108:D', 'problem_106:A']),\n        2.0, ..., 5.0, 1.0, 13.0],\n       ...,\n       ['user_zltzlt',\n        list(['problem_1422:C', 'problem_1422:D', 'problem_1422:A', 'problem_1422:B', 'problem_1421:D', 'problem_1624:D', 'problem_1624:F', 'problem_1624:G', 'problem_1624:E', 'problem_1626:C']),\n        1.0, ..., 3.0, 46.0, 17.0],\n       ['user_zltzlt',\n        list(['problem_1422:A', 'problem_1422:B', 'problem_1421:D', 'problem_1624:D', 'problem_1624:F', 'problem_1624:G', 'problem_1624:E', 'problem_1626:C']),\n        1.0, ..., 3.0, 46.0, 17.0],\n       ['user_zltzlt', list(['problem_1624:E', 'problem_1626:C']), 1.0,\n        ..., 3.0, 46.0, 17.0]], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"DataLoader is defined to be used for training and evaluation as final pre-processing step.","metadata":{"id":"XVKMFIwd_6vK"}},{"cell_type":"code","source":"# Pytorch Dataset for user interactions\nclass problemSeqDataset(Dataset):\n    # Initialize dataset\n    def __init__(self, data, problem_vocab_stoi, user_vocab_stoi):\n        self.data = data\n        self.problem_vocab_stoi = problem_vocab_stoi\n        self.user_vocab_stoi = user_vocab_stoi\n\n\n    def __len__(self):\n        return len(self.data)\n\n    # Fetch data from the dataset\n    def __getitem__(self, idx):\n        user = self.data[idx][0]\n        problem_sequence = self.data[idx][1]\n        # Directly index into the vocabularies\n        problem_data = [self.problem_vocab_stoi[item] for item in problem_sequence]\n        user_data = self.user_vocab_stoi[user]\n        \n        # Create a dictionary to hold all features\n        encoded_features = {\n            'problem_data': torch.tensor(problem_data),\n            'user_data': torch.tensor(user_data)\n        }\n        \n        # Add other features to the dictionary\n        for i, feature in enumerate(self.data[idx][2:]):\n            feature_name = f'feature_{i+1}'\n            encoded_features[feature_name] = torch.tensor(feature).int()\n            \n        return encoded_features\n\n\n# Collate function and padding\ndef collate_batch(batch):\n    # Extract tensors for problem and user data\n    problem_list = [item['problem_data'] for item in batch]\n    user_list = [item['user_data'] for item in batch]\n    \n    # Pad problem sequences\n    padded_problem = pad_sequence(problem_list, padding_value=problem_vocab_stoi['<unk>'], batch_first=True)\n    \n    # Stack user data\n    user_data = torch.stack(user_list)\n#     print(\"HELOOOO\", user_data.shape)\n    \n    # Prepare a dictionary to hold all features\n    collated_batch = {\n        'problem_data': padded_problem,\n        'user_data': user_data,\n    }\n    \n    # Add other features to the collated batch\n    for i in range(1, len(batch[0].keys()) - 1): \n        feature_name = f'feature_{i}'\n        feature_list = [item[feature_name] for item in batch]\n        collated_batch[feature_name] = torch.stack(feature_list)\n    \n    return collated_batch\n\n\nBATCH_SIZE = 256\n# Create instances of your Dataset for each set\ntrain_dataset = problemSeqDataset(train_data_raw, problem_vocab_stoi, user_vocab_stoi)\nval_dataset = problemSeqDataset(test_data_raw, problem_vocab_stoi, user_vocab_stoi)\n\n# Create DataLoaders\ntrain_iter = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                        shuffle=True, collate_fn=collate_batch)\nval_iter = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                      shuffle=False, collate_fn=collate_batch)\n","metadata":{"id":"YAjJ0nTp_4uX","execution":{"iopub.status.busy":"2024-04-29T20:18:27.918421Z","iopub.execute_input":"2024-04-29T20:18:27.918778Z","iopub.status.idle":"2024-04-29T20:18:27.935480Z","shell.execute_reply.started":"2024-04-29T20:18:27.918749Z","shell.execute_reply":"2024-04-29T20:18:27.934482Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"print(train_dataset[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q9Ti_gWjr9jz","outputId":"1a36bf1b-46c2-4b69-f645-bd7749dda8b1","execution":{"iopub.status.busy":"2024-04-29T20:18:27.936463Z","iopub.execute_input":"2024-04-29T20:18:27.936744Z","iopub.status.idle":"2024-04-29T20:18:27.951381Z","shell.execute_reply.started":"2024-04-29T20:18:27.936710Z","shell.execute_reply":"2024-04-29T20:18:27.950444Z"},"trusted":true},"execution_count":170,"outputs":[{"name":"stdout","text":"{'problem_data': tensor([3893, 4777, 1152, 1021, 1028, 5324, 5323, 5854,  256, 2948, 3548, 3547,\n        1007,  359, 3828, 2952,  989,  990, 3867, 3550]), 'user_data': tensor(96), 'feature_1': tensor(2, dtype=torch.int32), 'feature_2': tensor(0, dtype=torch.int32), 'feature_3': tensor(21, dtype=torch.int32), 'feature_4': tensor(2, dtype=torch.int32), 'feature_5': tensor(43, dtype=torch.int32), 'feature_6': tensor(0, dtype=torch.int32), 'feature_7': tensor(7, dtype=torch.int32), 'feature_8': tensor(53, dtype=torch.int32), 'feature_9': tensor(17, dtype=torch.int32), 'feature_10': tensor(3, dtype=torch.int32), 'feature_11': tensor(1, dtype=torch.int32), 'feature_12': tensor(20, dtype=torch.int32), 'feature_13': tensor(2, dtype=torch.int32), 'feature_14': tensor(0, dtype=torch.int32), 'feature_15': tensor(0, dtype=torch.int32), 'feature_16': tensor(0, dtype=torch.int32), 'feature_17': tensor(9, dtype=torch.int32), 'feature_18': tensor(10, dtype=torch.int32), 'feature_19': tensor(0, dtype=torch.int32), 'feature_20': tensor(5, dtype=torch.int32), 'feature_21': tensor(117, dtype=torch.int32), 'feature_22': tensor(1, dtype=torch.int32), 'feature_23': tensor(106, dtype=torch.int32), 'feature_24': tensor(0, dtype=torch.int32), 'feature_25': tensor(101, dtype=torch.int32), 'feature_26': tensor(0, dtype=torch.int32), 'feature_27': tensor(0, dtype=torch.int32), 'feature_28': tensor(13, dtype=torch.int32), 'feature_29': tensor(2, dtype=torch.int32), 'feature_30': tensor(1, dtype=torch.int32), 'feature_31': tensor(1, dtype=torch.int32), 'feature_32': tensor(33, dtype=torch.int32), 'feature_33': tensor(0, dtype=torch.int32), 'feature_34': tensor(26, dtype=torch.int32), 'feature_35': tensor(5, dtype=torch.int32), 'feature_36': tensor(1, dtype=torch.int32), 'feature_37': tensor(13, dtype=torch.int32)}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Model Definition\nIn this section we will define and initialize our model. Then the model will be trained with our previously generated dataset.\n## 2.1 Positional Encoder\nWe start by defining the positional encoder, which is crucial for sequence-based models like the Transformer. This encoder will capture the positions of problem interactions in our sequences, thus embedding the order information that the Transformer model needs.","metadata":{"id":"ZRSuW2NXAkfk"}},{"cell_type":"code","source":"# class PositionalEncoding(nn.Module):\n\n#     def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n#         super().__init__()\n#         self.dropout = nn.Dropout(p=dropout)\n\n#         position = torch.arange(max_len).unsqueeze(1)\n\n#         # `div_term` is used in the calculation of the sinusoidal values.\n#         div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n\n#         # Initializing positional encoding matrix with zeros.\n#         pe = torch.zeros(max_len, 1, d_model)\n\n#         # Calculating the positional encodings.\n#         pe[:, 0, 0::2] = torch.sin(position * div_term)\n#         pe[:, 0, 1::2] = torch.cos(position * div_term)\n#         self.register_buffer('pe', pe)\n\n#     def forward(self, x: Tensor) -> Tensor:\n#         \"\"\"\n#         Arguments:\n#             x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n#         \"\"\"\n#         x = x + self.pe[:x.size(0)]\n#         return self.dropout(x)","metadata":{"id":"YIOSMBCtAanG","execution":{"iopub.status.busy":"2024-04-29T20:18:27.953005Z","iopub.execute_input":"2024-04-29T20:18:27.953786Z","iopub.status.idle":"2024-04-29T20:18:27.958138Z","shell.execute_reply.started":"2024-04-29T20:18:27.953751Z","shell.execute_reply":"2024-04-29T20:18:27.957277Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Transformer Model\nFollowing the definition of our positional encoder, we then establish our transformer model. This model takes both the user id and the problem id sequence as input, and it is responsible for generating the output problem predictions.","metadata":{"id":"Z4wtPnqQAsOU"}},{"cell_type":"code","source":"# class TransformerModel(nn.Module):\n#     def __init__(self, ntoken: int, nuser: int, d_model: int, nhead: int, d_hid: int,\n#                  nlayers: int, dropout: float = 0.5):\n#         super().__init__()\n#         self.model_type = 'Transformer'\n#         # positional encoder\n#         self.pos_encoder = PositionalEncoding(d_model, dropout)\n\n#         # Multihead attention mechanism.\n#         encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n#         self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n\n#         # Embedding layers\n#         self.problem_embedding = nn.Embedding(ntoken, d_model)\n#         self.user_embedding = nn.Embedding(nuser, d_model)\n#         self.feature_embedding = nn.Embedding(1000, d_model)\n\n#         # Defining the size of the input to the model.\n#         self.d_model = d_model\n\n#         # Linear layer to map the output toproblem vocabulary.\n#         self.linear = nn.Linear(31*d_model, ntoken)\n\n#         self.init_weights()\n\n#     def init_weights(self) -> None:\n#         # Initializing the weights of the embedding and linear layers.\n#         initrange = 0.1\n#         self.problem_embedding.weight.data.uniform_(-initrange, initrange)\n#         self.user_embedding.weight.data.uniform_(-initrange, initrange)\n#         self.linear.bias.data.zero_()\n#         self.linear.weight.data.uniform_(-initrange, initrange)\n\n#     def forward(self, src: Tensor, user: Tensor, other_features_batch, src_mask: Tensor = None) -> Tensor:\n#         # Embedding problem ids and userid\n#         problem_embed = self.problem_embedding(src) * math.sqrt(self.d_model)\n#         user_embed = self.user_embedding(user) * math.sqrt(self.d_model)\n        \n# #         print(\"problem_embed shape:\", problem_embed.shape)\n# #         print(\"user_embed shape:\", user_embed.shape)\n\n#         # positional encoding\n#         problem_embed = self.pos_encoder(problem_embed)\n\n#         # generating output with final layers\n#         output = self.transformer_encoder(problem_embed, src_mask)\n        \n# #         print(\"lstm_output\", output.shape)\n\n#         # Expand user_embed tensor along the sequence length dimension\n#         user_embed = user_embed.expand(-1, output.size(1), -1)\n#         other_features_embed = []\n#         for i, (feature_name, feature_tensor) in enumerate(other_features_batch.items()):\n#             other_feature_embedding = self.feature_embedding(feature_tensor)* math.sqrt(self.d_model)\n#             other_features_embed.append(other_feature_embedding)\n        \n#         other_features_embed = torch.cat(other_features_embed, dim=-1)\n#         other_features_embed = other_features_embed.expand(-1, output.size(1), -1)\n        \n# #         print(\"user_embed\", user_embed.shape)\n\n#         # Concatenate user embeddings with transformer output\n#         output = torch.cat((output, user_embed, other_features_embed), dim=-1)\n        \n# #         print(\"hello\", output.shape)\n\n#         output = self.linear(output)\n#         return output\n","metadata":{"id":"Zef8tq8NAo7M","execution":{"iopub.status.busy":"2024-04-29T20:18:27.959720Z","iopub.execute_input":"2024-04-29T20:18:27.960542Z","iopub.status.idle":"2024-04-29T20:18:27.969721Z","shell.execute_reply.started":"2024-04-29T20:18:27.960508Z","shell.execute_reply":"2024-04-29T20:18:27.968880Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"class LSTMModel(nn.Module):\n    def __init__(self, ntoken: int, nuser: int, d_model: int, d_hid: int, nlayers: int, dropout: float = 0.5):\n        super().__init__()\n        self.model_type = 'LSTM'\n\n        # Embedding layers\n        self.problem_embedding = nn.Embedding(ntoken, d_model)\n        self.user_embedding = nn.Embedding(nuser, d_model)\n        self.feature_embedding = nn.Embedding(1000, d_model)\n\n        # LSTM layers\n        self.lstm = nn.GRU(d_model, d_hid, nlayers, batch_first=True, dropout=dropout)\n\n        self.d_model = d_model\n\n        # Linear layer to map the LSTM output to problem vocabulary\n        self.linear = nn.Linear(39*d_hid, ntoken)\n#         self.linear = nn.Sequential(\n#             nn.Linear(31*d_hid,31*d_hid//2),\n#             nn.Linear(31*d_hid//2, 31*d_hid//4),\n#             nn.Dropout(0.2),\n#             nn.Linear(31*d_hid//4, 31*d_hid//8),\n#             nn.Linear(31*d_hid//8, ntoken)\n#         )\n\n        self.init_weights()\n\n    def init_weights(self) -> None:\n        # Initializing the weights of the embedding and linear layers\n        initrange = 0.1\n        self.problem_embedding.weight.data.uniform_(-initrange, initrange)\n        self.user_embedding.weight.data.uniform_(-initrange, initrange)\n        self.feature_embedding.weight.data.uniform_(-initrange, initrange)\n        self.linear.bias.data.zero_()\n        self.linear.weight.data.uniform_(-initrange, initrange)\n\n    def forward(self, src: Tensor, user: Tensor, other_features_batch) -> Tensor:\n        # Embedding problem ids and user id\n        \n#         print(\"user shape\",user.shape)\n        problem_embed = self.problem_embedding(src)* math.sqrt(self.d_model)\n        user_embed = self.user_embedding(user)* math.sqrt(self.d_model)\n        \n        # print(\"problem_embed shape:\", problem_embed.shape)\n#         print(\"user_embed shape:\", user_embed.shape)\n\n        # Pass the combined embeddings through LSTM layers\n        lstm_output, _ = self.lstm(problem_embed)\n        \n#         print(\"lstm_output\", lstm_output.shape)\n        \n        other_features_embed = []\n        for i, (feature_name, feature_tensor) in enumerate(other_features_batch.items()):\n#             print(f\"Processing other feature '{feature_name}'\")\n#             print(\"Feature tensor shape:\", feature_tensor.shape)\n            other_feature_embedding = self.feature_embedding(feature_tensor)* math.sqrt(self.d_model)\n            other_features_embed.append(other_feature_embedding)\n#             print(\"Other feature embedding shape:\", other_feature_embedding.shape)\n        \n        \n        other_features_embed = torch.cat(other_features_embed, dim=-1)\n        other_features_embed = other_features_embed.expand(-1, lstm_output.size(1), -1)\n\n        user_embed = user_embed.expand(-1, lstm_output.size(1), -1)\n#         print(\"user_embed after expansion\", user_embed.shape)\n\n        output = torch.cat((lstm_output, user_embed, other_features_embed), dim=-1)\n\n        # print(\"hello\", output.shape)\n\n        # Apply linear layer to obtain the output logits\n        output = self.linear(output)\n\n        return output\n","metadata":{"id":"1ZG_plsZJdPd","execution":{"iopub.status.busy":"2024-04-29T20:18:27.970807Z","iopub.execute_input":"2024-04-29T20:18:27.971096Z","iopub.status.idle":"2024-04-29T20:18:27.985397Z","shell.execute_reply.started":"2024-04-29T20:18:27.971073Z","shell.execute_reply":"2024-04-29T20:18:27.984471Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"markdown","source":"Following the model definitions, we proceed to initialize our model using a set of arbitrarily selected hyperparameters.","metadata":{"id":"3M5XCLFG_LLi"}},{"cell_type":"code","source":"ntokens = len(problem_vocab)  # size of vocabulary\nnusers = len(user_vocab)\nd_model = 128  # embedding dimension (maybe 512?)\nd_hid = 128  # dimension of the LSTM hidden states\nnlayers = 2  # number of LSTM layers\ndropout = 0.2  # dropout probability\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = LSTMModel(ntokens, nusers, d_model, d_hid, nlayers, dropout).to(device)\n\ncriterion = nn.CrossEntropyLoss()\nlr = 1.0  # learning rate\noptimizer = torch.optim.SGD(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","metadata":{"id":"l-1mdFJ8JdPe","execution":{"iopub.status.busy":"2024-04-29T20:18:27.986508Z","iopub.execute_input":"2024-04-29T20:18:27.986858Z","iopub.status.idle":"2024-04-29T20:18:28.699715Z","shell.execute_reply.started":"2024-04-29T20:18:27.986819Z","shell.execute_reply":"2024-04-29T20:18:28.698929Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"# ntokens = len(problem_vocab)  # size of vocabulary\n# nusers = len(user_vocab)\n# emsize = 128  # embedding dimension\n# d_hid = 128  # dimension of the feedforward network model\n# nlayers = 2  # number of ``nn.TransformerEncoderLayer``\n# nhead = 2  # number of heads in ``nn.MultiheadAttention``\n# dropout = 0.2  # dropout probability\n\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# model = TransformerModel(ntokens, nusers, emsize, nhead, d_hid, nlayers, dropout).to(device)\n\n# criterion = nn.CrossEntropyLoss()\n# lr = 1.0  # learning rate\n# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)","metadata":{"id":"8pEgP1gg-re5","execution":{"iopub.status.busy":"2024-04-29T20:18:28.701117Z","iopub.execute_input":"2024-04-29T20:18:28.701420Z","iopub.status.idle":"2024-04-29T20:18:28.705512Z","shell.execute_reply.started":"2024-04-29T20:18:28.701396Z","shell.execute_reply":"2024-04-29T20:18:28.704665Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"markdown","source":"# 3. Train & Evaluation\nWe're now ready to kick off the training process with our model, where it will learn from the dataset we've prepared. Following the training phase, we'll evaluate how well our model performs on unseen data to check its effectiveness.\n## 3.1 Train Function","metadata":{"id":"6c8xnSds_Pf-"}},{"cell_type":"code","source":"def train(model: nn.Module, train_iter, epoch) -> None:\n    # Switch to training mode\n    model.train()\n    total_loss = 0.\n    log_interval = 200\n    start_time = time.time()\n\n    for i, batch in enumerate(train_iter):\n        # Unpack the batch\n        problem_data_batch = batch['problem_data']\n        user_data_batch = batch['user_data']\n        other_features_batch = {k: v for k, v in batch.items() if k not in ['problem_data', 'user_data']}\n        \n#         print(\"user_data_batch.shape\", user_data_batch.shape)\n#         user_data_batch = user_data_batch.unsqueeze(1)\n        user_data_batch = user_data_batch.reshape(-1, 1)\n        \n#         print(\"user_data_batch.shape after squeeze\", user_data_batch.shape)\n        \n        # Move tensors to the appropriate device\n        problem_data_batch = problem_data_batch.to(device)\n        user_data_batch = user_data_batch.to(device)\n        for k, v in other_features_batch.items():\n            v=v.unsqueeze(1)\n            other_features_batch[k] = v.to(device)\n        \n        # Split problem sequence to inputs and targets\n        inputs, targets = problem_data_batch[:, :-1], problem_data_batch[:, 1:]\n        targets_flat = targets.reshape(-1)\n        \n#         if (i==0):\n#             print(problem_data_batch[0])\n#             print('\\n',inputs[0])\n#             print('\\n',targets[0])\n#             print(\"inputs\",inputs.shape)\n#             print(\"user_data_batch\", user_data_batch.shape)\n#             for k, v in other_features_batch.items():\n#                 print('\\n', k, v.shape)\n#             print(\"targets\",targets.shape)\n#             print(\"targets_flat\",targets_flat.shape)\n            \n\n        # Predict problems\n        output = model(inputs, user_data_batch, other_features_batch)\n\n        # Compute the loss\n        loss = criterion(output.view(-1, ntokens), targets_flat)\n        \n#         if (i==0):\n#             print(\"output_shape\", output.shape)\n#             print(\"output_shape_2\",output.view(-1, ntokens).shape)\n\n        # Perform backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n        optimizer.step()\n\n        total_loss += loss.item()\n\n        # Print training progress\n        if i % log_interval == 0 and i > 0:\n            lr = scheduler.get_last_lr()[0]\n            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n            cur_loss = total_loss / log_interval\n            ppl = math.exp(cur_loss)\n            print(f'| epoch {epoch:3d} '\n                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n            total_loss = 0\n            start_time = time.time()\n","metadata":{"id":"gW7vxqTV_Kn-","execution":{"iopub.status.busy":"2024-04-29T20:18:28.706926Z","iopub.execute_input":"2024-04-29T20:18:28.707292Z","iopub.status.idle":"2024-04-29T20:18:28.719778Z","shell.execute_reply.started":"2024-04-29T20:18:28.707260Z","shell.execute_reply":"2024-04-29T20:18:28.718963Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"# def train(model: nn.Module, train_iter, epoch) -> None:\n#     # Switch to training mode\n#     model.train()\n#     total_loss = 0.\n#     log_interval = 200\n#     start_time = time.time()\n\n#     for i, batch in enumerate(train_iter):\n#         # Unpack the batch\n#         problem_data_batch = batch['problem_data']\n#         user_data_batch = batch['user_data']\n#         other_features_batch = {k: v for k, v in batch.items() if k not in ['problem_data', 'user_data']}\n        \n# #         print(\"user_data_batch.shape\", user_data_batch.shape)\n# #         user_data_batch = user_data_batch.unsqueeze(1)\n#         user_data_batch = user_data_batch.reshape(-1, 1)\n        \n# #         print(\"user_data_batch.shape after squeeze\", user_data_batch.shape)\n        \n#         # Move tensors to the appropriate device\n#         problem_data_batch = problem_data_batch.to(device)\n#         user_data_batch = user_data_batch.to(device)\n#         for k, v in other_features_batch.items():\n#             v=v.unsqueeze(1)\n#             other_features_batch[k] = v.to(device)\n        \n#         # Split problem sequence to inputs and targets\n#         inputs, targets = problem_data_batch[:, :-1], problem_data_batch[:, 1:]\n#         targets_flat = targets.reshape(-1)\n        \n# #         if (i==0):\n# #             print(problem_data_batch[0])\n# #             print('\\n',inputs[0])\n# #             print('\\n',targets[0])\n# #             print(\"inputs\",inputs.shape)\n# #             print(\"user_data_batch\", user_data_batch.shape)\n# #             for k, v in other_features_batch.items():\n# #                 print('\\n', k, v.shape)\n# #             print(\"targets\",targets.shape)\n# #             print(\"targets_flat\",targets_flat.shape)\n            \n\n#         # Predict problems\n#         output = model(inputs, user_data_batch, other_features_batch)\n\n#         # Compute the loss\n#         loss = criterion(output.view(-1, ntokens), targets_flat)\n        \n# #         if (i==0):\n# #             print(\"output_shape\", output.shape)\n# #             print(\"output_shape_2\",output.view(-1, ntokens).shape)\n\n#         # Perform backpropagation\n#         optimizer.zero_grad()\n#         loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n#         optimizer.step()\n\n#         total_loss += loss.item()\n\n#         # Print training progress\n#         if i % log_interval == 0 and i > 0:\n#             lr = scheduler.get_last_lr()[0]\n#             ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n#             cur_loss = total_loss / log_interval\n#             ppl = math.exp(cur_loss)\n#             print(f'| epoch {epoch:3d} '\n#                   f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n#                   f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n#             total_loss = 0\n#             start_time = time.time()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:18:28.720955Z","iopub.execute_input":"2024-04-29T20:18:28.721257Z","iopub.status.idle":"2024-04-29T20:18:28.732678Z","shell.execute_reply.started":"2024-04-29T20:18:28.721214Z","shell.execute_reply":"2024-04-29T20:18:28.731863Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Evaluation Function","metadata":{"id":"VKnPqYte_6si"}},{"cell_type":"code","source":"def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n    # Switch the model to evaluation mode.\n    # This is necessary for layers like dropout,\n    model.eval()\n    total_loss = 0.\n\n    with torch.no_grad():\n        for i, batch in enumerate(train_iter):\n        # Unpack the batch\n            problem_data_batch = batch['problem_data']\n            user_data_batch = batch['user_data']\n            other_features_batch = {k: v for k, v in batch.items() if k not in ['problem_data', 'user_data']}\n\n            # Move tensors to the appropriate device\n            problem_data_batch = problem_data_batch.to(device)\n            user_data_batch = user_data_batch.to(device)\n            \n            user_data_batch = user_data_batch.reshape(-1, 1)\n            \n            for k, v in other_features_batch.items():\n                v = v.unsqueeze(1)\n                other_features_batch[k] = v.to(device)\n                \n            # Split problem sequence to inputs and targets\n            inputs, targets = problem_data_batch[:, :-1], problem_data_batch[:, 1:]\n            targets_flat = targets.reshape(-1)\n\n            # Predict problems\n            output = model(inputs, user_data_batch,other_features_batch)\n\n            # Calculate loss\n            loss = criterion(output.view(-1, ntokens), targets_flat)  # Reshape output for loss calculation\n            total_loss += loss.item()\n\n    # Return average loss over all batches\n    return total_loss / len(eval_data)\n","metadata":{"id":"ex23S0dK_kM3","execution":{"iopub.status.busy":"2024-04-29T20:18:28.733755Z","iopub.execute_input":"2024-04-29T20:18:28.734036Z","iopub.status.idle":"2024-04-29T20:18:28.744722Z","shell.execute_reply.started":"2024-04-29T20:18:28.734013Z","shell.execute_reply":"2024-04-29T20:18:28.743901Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"# def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n#     # Switch the model to evaluation mode.\n#     # This is necessary for layers like dropout,\n#     model.eval()\n#     total_loss = 0.\n\n#     with torch.no_grad():\n#         for i, batch in enumerate(train_iter):\n#         # Unpack the batch\n#             problem_data_batch = batch['problem_data']\n#             user_data_batch = batch['user_data']\n#             other_features_batch = {k: v for k, v in batch.items() if k not in ['problem_data', 'user_data']}\n\n#             # Move tensors to the appropriate device\n#             problem_data_batch = problem_data_batch.to(device)\n#             user_data_batch = user_data_batch.to(device)\n            \n#             user_data_batch = user_data_batch.reshape(-1, 1)\n            \n#             for k, v in other_features_batch.items():\n#                 v = v.unsqueeze(1)\n#                 other_features_batch[k] = v.to(device)\n                \n#             # Split problem sequence to inputs and targets\n#             inputs, targets = problem_data_batch[:, :-1], problem_data_batch[:, 1:]\n#             targets_flat = targets.reshape(-1)\n\n#             # Predict problems\n#             output = model(inputs, user_data_batch,other_features_batch)\n\n#             # Calculate loss\n#             loss = criterion(output.view(-1, ntokens), targets_flat)  # Reshape output for loss calculation\n#             total_loss += loss.item()\n\n#     # Return average loss over all batches\n#     return total_loss / len(eval_data)\n","metadata":{"id":"DoeQ8_SyJdPf","execution":{"iopub.status.busy":"2024-04-29T20:18:28.745748Z","iopub.execute_input":"2024-04-29T20:18:28.746049Z","iopub.status.idle":"2024-04-29T20:18:28.755747Z","shell.execute_reply.started":"2024-04-29T20:18:28.746024Z","shell.execute_reply":"2024-04-29T20:18:28.754850Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Train & Evaluation Loop","metadata":{"id":"qJNdsU06_2ky"}},{"cell_type":"code","source":"best_val_loss = float('inf')\nepochs = 30\n\nwith TemporaryDirectory() as tempdir:\n    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n\n    for epoch in range(1, epochs + 1):\n        epoch_start_time = time.time()\n\n        # Training\n        train(model, train_iter, epoch)\n\n        # Evaluation\n        val_loss = evaluate(model, val_iter)\n        \n        elapsed = time.time() - epoch_start_time\n\n        # Results\n        print('-' * 89)\n        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n            f'valid loss {val_loss:5.2f}')\n        print('-' * 89)\n\n        # Save best model\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), best_model_params_path)\n\n        scheduler.step()\n\n    # After training, load the best model parameters\n    model.load_state_dict(torch.load(best_model_params_path))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGs7vxT0_18W","outputId":"411f88b5-0803-4c0e-e799-6703c979d4d2","execution":{"iopub.status.busy":"2024-04-29T20:18:28.756939Z","iopub.execute_input":"2024-04-29T20:18:28.757322Z","iopub.status.idle":"2024-04-29T20:19:23.089550Z","shell.execute_reply.started":"2024-04-29T20:18:28.757291Z","shell.execute_reply":"2024-04-29T20:19:23.088638Z"},"trusted":true},"execution_count":180,"outputs":[{"name":"stdout","text":"-----------------------------------------------------------------------------------------\n| end of epoch   1 | time: 26.73s | valid loss 47.02\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   2 | time: 26.65s | valid loss 44.01\n-----------------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3.4 Generating Popular problem Recommendations as Baseline\nIn order to compare our model success a baseline recommendation method is required. One of the easiest recommendation method is popular problem recommendation which is obtained by most frequent and highly rated problems.","metadata":{"id":"RDZJozuLjIUw"}},{"cell_type":"code","source":"# def get_popular_problems(interactions):\n#   # Calculate the number of ratings for each problem\n#   rating_counts = interactions['problem_id'].value_counts().reset_index()\n#   rating_counts.columns = ['problem_id', 'rating_count']\n\n#   # Get the most frequently rated problems\n#   min_ratings_threshold = rating_counts['rating_count'].quantile(0.95)\n\n#   # Filter problems based on the minimum number of ratings\n#   popular_problems = interactions.merge(rating_counts, on='problem_id')\n#   popular_problems = popular_problems[popular_problems['rating_count'] >= min_ratings_threshold]\n\n\n#   # Calculate the average rating for each problem\n#   average_ratings = popular_problems.groupby('problem_id')['rating'].mean().reset_index()\n#   # Get the top 10 rated problems\n#   top_10_problems = list(average_ratings.sort_values('rating', ascending=False).head(10).problem_id.values)\n#   return top_10_problems","metadata":{"id":"_buSM6b5YHuK","execution":{"iopub.status.busy":"2024-04-29T20:19:23.090999Z","iopub.execute_input":"2024-04-29T20:19:23.091347Z","iopub.status.idle":"2024-04-29T20:19:23.101013Z","shell.execute_reply.started":"2024-04-29T20:19:23.091319Z","shell.execute_reply":"2024-04-29T20:19:23.099975Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"# top_10_problems = get_popular_problems(interactions)\n# [problem_title_dict[problem] for problem in top_10_problems]","metadata":{"id":"bDY4JvP-o3xZ","execution":{"iopub.status.busy":"2024-04-29T20:19:23.102261Z","iopub.execute_input":"2024-04-29T20:19:23.102566Z","iopub.status.idle":"2024-04-29T20:19:23.662800Z","shell.execute_reply.started":"2024-04-29T20:19:23.102541Z","shell.execute_reply":"2024-04-29T20:19:23.661836Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"markdown","source":"## 3.5 Recommendations Result Comparison\nLike the evaluation function we will iterate our validation dataset and store recommendation results in lists to compare them with normalized discounted gain(NDCG) metric.","metadata":{"id":"z9edNBt-ijnA"}},{"cell_type":"code","source":"# # problem id decoder\n# problem_vocab_itos = problem_vocab.get_itos()\n\n# # A placeholders to store results of recommendations\n# transformer_reco_results = list()\n# popular_reco_results = list()\n\n# # Get top 10 problems\n# k = 10\n# # Iterate over the validation data\n# for i, (problem_data, user_data) in enumerate(val_iter):\n#     # Feed the input and get the outputs\n#     problem_data, user_data = problem_data.to(device), user_data.to(device)\n#     user_data = user_data.reshape(-1, 1)\n#     inputs, targets = problem_data[:, :-1], problem_data[:, 1:]\n#     output = model(inputs, user_data)\n#     output_flat = output.reshape(-1, ntokens)\n#     targets_flat = targets.reshape(-1)\n\n#     # Reshape the output_flat to get top predictions\n#     outputs = output_flat.reshape(output_flat.shape[0] // inputs.shape[1],\n#                                   inputs.shape[1],\n#                                   output_flat.shape[1])[: , -1, :]\n#     # k + len(inputs) = 13 problems obtained\n#     # In order to prevent to recommend already watched problems\n#     values, indices = outputs.topk(k + inputs.shape[1], dim=-1)\n\n#     for sub_sequence, sub_indice_org in zip(problem_data, indices):\n#         sub_indice_org = sub_indice_org.cpu().detach().numpy()\n#         sub_sequence = sub_sequence.cpu().detach().numpy()\n\n#         # Generate mask array to eliminate already watched problems\n#         mask = np.isin(sub_indice_org, sub_sequence[:-1], invert=True)\n\n#         # After masking get top k problems\n#         sub_indice = sub_indice_org[mask][:k]\n\n#         # Generate results array\n#         transformer_reco_result = np.isin(sub_indice, sub_sequence[-1]).astype(int)\n\n#         # Decode problem to search in popular problems\n#         target_problem_decoded = problem_vocab_itos[sub_sequence[-1]]\n#         popular_reco_result = np.isin(top_10_problems, target_problem_decoded).astype(int)\n\n#         transformer_reco_results.append(transformer_reco_result)\n#         popular_reco_results.append(popular_reco_result)","metadata":{"id":"7XtOtvbCamoA","execution":{"iopub.status.busy":"2024-04-29T20:19:23.664211Z","iopub.execute_input":"2024-04-29T20:19:23.664580Z","iopub.status.idle":"2024-04-29T20:19:23.672523Z","shell.execute_reply.started":"2024-04-29T20:19:23.664549Z","shell.execute_reply":"2024-04-29T20:19:23.671600Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"markdown","source":"After generating result for each recommendation now time to compare baseline method vs transformer model.","metadata":{"id":"lWid7M9fbx7g"}},{"cell_type":"code","source":"# from sklearn.metrics import ndcg_score\n\n# # Since we have already sorted our recommendations\n# # An array that represent our recommendation scores is used.\n# representative_array = [[i for i in range(k, 0, -1)]] * len(transformer_reco_results)\n\n# for k in [3, 5, 10]:\n#   transformer_result = ndcg_score(transformer_reco_results,\n#                                   representative_array, k=k)\n#   popular_result = ndcg_score(popular_reco_results,\n#                               representative_array, k=k)\n\n#   print(f\"Transformer NDCG result at top {k}: {round(transformer_result, 4)}\")\n#   print(f\"Popular recommendation NDCG result at top {k}: {round(popular_result, 4)}\\n\\n\")\n","metadata":{"id":"6DYVH2JmpHrW","execution":{"iopub.status.busy":"2024-04-29T20:19:23.673788Z","iopub.execute_input":"2024-04-29T20:19:23.674449Z","iopub.status.idle":"2024-04-29T20:19:23.684142Z","shell.execute_reply.started":"2024-04-29T20:19:23.674421Z","shell.execute_reply":"2024-04-29T20:19:23.683346Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"markdown","source":"Here we have seen our model results are approximately 10 times better than popular problem recommendation at NDCG metric. A function to generate recommendation for single data is given below.","metadata":{"id":"3rvyhAueb2f9"}},{"cell_type":"code","source":"def generate_recommendation(data, k=5):\n    model.eval()\n    user_id = data[0];\n    problem_sequence = data[1];\n    input_sequence = problem_sequence[:-1]\n    # Tokenize and numerically encode the user id and problem sequence\n    user_tensor = torch.tensor(user_vocab_stoi[user_id])\n    problem_tensor = torch.tensor([[problem_vocab_stoi[problem_id]] for problem_id in input_sequence])\n    # Shape: [1, 1]\n    user_tensor = user_tensor.unsqueeze(0).to(device)\n    user_tensor = user_tensor.view(user_tensor.shape[0], 1)\n\n    # Shape: [1, seq_length]\n    problem_tensor = problem_tensor.unsqueeze(0).to(device)[0]\n    problem_tensor = problem_tensor.view(1, problem_tensor.shape[0])\n    \n    other_features_batch={}\n    \n    for i, feature in enumerate(data[2:]):\n            feature_name = f'feature_{i+1}'\n            other_features_batch[feature_name] = torch.tensor(feature).int()\n            other_features_batch[feature_name] = other_features_batch[feature_name].unsqueeze(0).to(device)\n            other_features_batch[feature_name] = other_features_batch[feature_name].view(other_features_batch[feature_name].shape[0], 1)\n    \n#     print(\"user_tensor\", user_tensor.shape)\n#     print(\"problem_tensor\", problem_tensor.shape)\n\n    # Pass the tensors through the model\n    with torch.no_grad():\n        predictions = model(problem_tensor, user_tensor, other_features_batch)\n\n    # The output is a probability distribution over the next problem.\n    # Topk to get most probable problems\n    values, indices = predictions.topk(k + len(input_sequence), dim=-1)\n\n    # Eliminate already watched problems\n    indices = [indice for indice in indices[-1, :][0] if indice not in problem_tensor][:k]\n    predicted_problems = [problem_vocab.get_itos()[problem] for problem in indices]\n    return predicted_problems","metadata":{"id":"XAyDjSxV_pZa","execution":{"iopub.status.busy":"2024-04-29T20:19:23.685322Z","iopub.execute_input":"2024-04-29T20:19:23.685650Z","iopub.status.idle":"2024-04-29T20:19:23.698170Z","shell.execute_reply.started":"2024-04-29T20:19:23.685615Z","shell.execute_reply":"2024-04-29T20:19:23.697346Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"len(test_data_raw)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wm5PYvAhJdPr","outputId":"1fae2244-137c-41d4-f3b7-f4f8c8a95d88","execution":{"iopub.status.busy":"2024-04-29T20:19:23.699528Z","iopub.execute_input":"2024-04-29T20:19:23.699846Z","iopub.status.idle":"2024-04-29T20:19:23.710359Z","shell.execute_reply.started":"2024-04-29T20:19:23.699813Z","shell.execute_reply":"2024-04-29T20:19:23.709382Z"},"trusted":true},"execution_count":186,"outputs":[{"execution_count":186,"output_type":"execute_result","data":{"text/plain":"2034"},"metadata":{}}]},{"cell_type":"code","source":"row_iter = test_data_raw[970]\nprint(\"Input Sequence:\")\nprint(\"-\" + \"\\n-\".join([ea_problem for ea_problem in row_iter[1][:-1]]))\nrecos = '\\n-'.join(generate_recommendation(row_iter))\n\nprint(f\"Recomendations:\\n-{recos}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcuSBAP5fGXb","outputId":"2f870592-4cf2-4722-eb2d-edbe627180ff","execution":{"iopub.status.busy":"2024-04-29T20:19:23.712274Z","iopub.execute_input":"2024-04-29T20:19:23.712865Z","iopub.status.idle":"2024-04-29T20:19:23.729897Z","shell.execute_reply.started":"2024-04-29T20:19:23.712832Z","shell.execute_reply":"2024-04-29T20:19:23.729002Z"},"trusted":true},"execution_count":187,"outputs":[{"name":"stdout","text":"Input Sequence:\n-problem_1355:B\n-problem_1256:D\n-problem_1349:C\n-problem_1551:E\n-problem_1207:D\n-problem_1699:D\n-problem_1242:A\n-problem_1450:C1\n-problem_1420:A\n-problem_1213:A\n-problem_1182:A\n-problem_1206:B\n-problem_1146:B\n-problem_1417:B\n-problem_1354:B\n-problem_1208:A\n-problem_1339:A\n-problem_1374:C\n-problem_1254:A\nRecomendations:\n-problem_1132:F\n-problem_1228:D\n-problem_1490:G\n-problem_1613:E\n-problem_1430:E\n","output_type":"stream"}]},{"cell_type":"code","source":"row_iter","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEdOvaUV4CYQ","outputId":"c72ab208-d565-4732-f9aa-77adfba53824","execution":{"iopub.status.busy":"2024-04-29T20:19:23.730818Z","iopub.execute_input":"2024-04-29T20:19:23.731093Z","iopub.status.idle":"2024-04-29T20:19:23.736942Z","shell.execute_reply.started":"2024-04-29T20:19:23.731071Z","shell.execute_reply":"2024-04-29T20:19:23.735969Z"},"trusted":true},"execution_count":188,"outputs":[{"execution_count":188,"output_type":"execute_result","data":{"text/plain":"array(['user_aniket_kundu',\n       list(['problem_1355:B', 'problem_1256:D', 'problem_1349:C', 'problem_1551:E', 'problem_1207:D', 'problem_1699:D', 'problem_1242:A', 'problem_1450:C1', 'problem_1420:A', 'problem_1213:A', 'problem_1182:A', 'problem_1206:B', 'problem_1146:B', 'problem_1417:B', 'problem_1354:B', 'problem_1208:A', 'problem_1339:A', 'problem_1374:C', 'problem_1254:A', 'problem_1209:C']),\n       4.0, 3.0, 77.0, 54.0, 155, 1.0, 37.0, 181, 91, 31.0, 5.0, 131,\n       15.0, 0.0, 1.0, 4.0, 10.0, 15.0, 2.0, 43.0, 311, 13.0, 205, 19.0,\n       287, 5.0, 1.0, 73.0, 3.0, 1.0, 14.0, 98, 4.0, 58.0, 2.0, 21.0,\n       53.0], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"row_iter[0] = '<unk>'","metadata":{"id":"ABofSpZn_9WW","execution":{"iopub.status.busy":"2024-04-29T20:19:23.737959Z","iopub.execute_input":"2024-04-29T20:19:23.738244Z","iopub.status.idle":"2024-04-29T20:19:23.744083Z","shell.execute_reply.started":"2024-04-29T20:19:23.738201Z","shell.execute_reply":"2024-04-29T20:19:23.743370Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"row_iter","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7nU2pHxACf1","outputId":"c0ce9982-a80c-4ee6-f88c-aafc1ee70609","execution":{"iopub.status.busy":"2024-04-29T20:19:23.746855Z","iopub.execute_input":"2024-04-29T20:19:23.747398Z","iopub.status.idle":"2024-04-29T20:19:23.754993Z","shell.execute_reply.started":"2024-04-29T20:19:23.747374Z","shell.execute_reply":"2024-04-29T20:19:23.754173Z"},"trusted":true},"execution_count":190,"outputs":[{"execution_count":190,"output_type":"execute_result","data":{"text/plain":"array(['<unk>',\n       list(['problem_1355:B', 'problem_1256:D', 'problem_1349:C', 'problem_1551:E', 'problem_1207:D', 'problem_1699:D', 'problem_1242:A', 'problem_1450:C1', 'problem_1420:A', 'problem_1213:A', 'problem_1182:A', 'problem_1206:B', 'problem_1146:B', 'problem_1417:B', 'problem_1354:B', 'problem_1208:A', 'problem_1339:A', 'problem_1374:C', 'problem_1254:A', 'problem_1209:C']),\n       4.0, 3.0, 77.0, 54.0, 155, 1.0, 37.0, 181, 91, 31.0, 5.0, 131,\n       15.0, 0.0, 1.0, 4.0, 10.0, 15.0, 2.0, 43.0, 311, 13.0, 205, 19.0,\n       287, 5.0, 1.0, 73.0, 3.0, 1.0, 14.0, 98, 4.0, 58.0, 2.0, 21.0,\n       53.0], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"# user_vocab_stoi","metadata":{"id":"qdiI6gv-Aaip","execution":{"iopub.status.busy":"2024-04-29T20:19:23.756093Z","iopub.execute_input":"2024-04-29T20:19:23.756381Z","iopub.status.idle":"2024-04-29T20:19:23.761422Z","shell.execute_reply.started":"2024-04-29T20:19:23.756358Z","shell.execute_reply":"2024-04-29T20:19:23.760550Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"generate_recommendation(row_iter)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMr4txnX3u33","outputId":"06884062-2367-459d-c3da-f6751b53315c","execution":{"iopub.status.busy":"2024-04-29T20:19:40.947887Z","iopub.execute_input":"2024-04-29T20:19:40.948266Z","iopub.status.idle":"2024-04-29T20:19:40.969365Z","shell.execute_reply.started":"2024-04-29T20:19:40.948214Z","shell.execute_reply":"2024-04-29T20:19:40.968400Z"},"trusted":true},"execution_count":193,"outputs":[{"execution_count":193,"output_type":"execute_result","data":{"text/plain":"['problem_1433:F',\n 'problem_933:A',\n 'problem_999:E',\n 'problem_1490:G',\n 'problem_1523:A']"},"metadata":{}}]}]}